@article{acharjeeActivityRecognitionSystem2016,
  title = {Activity Recognition System Using Inbuilt Sensors of Smart Mobile Phone and Minimizing Feature Vectors},
  author = {Acharjee, Dulal and Mukherjee, Amitava and Mandal, J. K. and Mukherjee, Nandini},
  date = {2016-11},
  journaltitle = {Microsystem Technologies},
  shortjournal = {Microsyst Technol},
  volume = {22},
  number = {11},
  pages = {2715--2722},
  issn = {0946-7076, 1432-1858},
  doi = {10.1007/s00542-015-2551-2},
  url = {http://link.springer.com/10.1007/s00542-015-2551-2},
  urldate = {2022-03-19},
  abstract = {Mobile phone is becoming a very popular tool due to having various user friendly applications with all flexible options. It is highly popular for its light weight, wearable and comfortable uses. Many extrinsic habitat of human being can be monitored by the help of inbuilt sensors and its application software. This has appealing use for healthcare applications using exploitation of Ambient Intelligence for daily activity monitoring system. Here, a standard dataset of UCI HAR (University of California, Irvine, Human Activity Recognition, http://archive.ics.uci. edu) is used for analysis purpose. Naive Bayes Classifier is used for recognition of runtime activities minimizing dimension of large feature vectors. Threshold based condition box is designed by us and finally these two results are compared with that of another classifier HF-SVM (Hardware Friendly-Support Vector Machine) of previous related work.},
  langid = {english},
  file = {C\:\\Users\\USER\\Zotero\\storage\\K9WVV2IL\\Acharjee et al. - 2016 - Activity recognition system using inbuilt sensors .pdf}
}

@article{ahujaDetectingVehicleType,
  title = {Detecting {{Vehicle Type}} and {{License Plate Number}} of Different {{Vehicles}} on {{Images}}},
  author = {Ahuja, Aashna and Chaudhuri, Arindam},
  abstract = {With ever increasing number of vehicles, vehicular tracking is one of the major challenges faced by urban areas. In this paper we try to develop a model that can locate a particular vehicle that the user is looking for depending on two factors 1. the Type of vehicle and the 2. License plate number of the car. The proposed system uses a unique mixture consisting of Mask RCNN model for vehicle type detection, WpodNet and pytesseract for License Plate detection and Prediction of letters in it.},
  langid = {english},
  file = {C\:\\Users\\USER\\Zotero\\storage\\KS72STPI\\Ahuja and Chaudhuri - Detecting Vehicle Type and License Plate Number of.pdf}
}

@inproceedings{antonyQuantifyingRadiographicKnee2016,
  title = {Quantifying Radiographic Knee Osteoarthritis Severity Using Deep Convolutional Neural Networks},
  booktitle = {2016 23rd {{International Conference}} on {{Pattern Recognition}} ({{ICPR}})},
  author = {Antony, Joseph and McGuinness, Kevin and O'Connor, Noel E and Moran, Kieran},
  date = {2016-12},
  pages = {1195--1200},
  publisher = {{IEEE}},
  location = {{Cancun}},
  doi = {10.1109/ICPR.2016.7899799},
  url = {http://ieeexplore.ieee.org/document/7899799/},
  urldate = {2022-04-02},
  abstract = {This paper proposes a new approach to automatically quantify the severity of knee osteoarthritis (OA) from radiographs using deep convolutional neural networks (CNN). Clinically, knee OA severity is assessed using Kellgren \& Lawrence (KL) grades, a five point scale. Previous work on automatically predicting KL grades from radiograph images were based on training shallow classifiers using a variety of hand engineered features. We demonstrate that classification accuracy can be significantly improved using deep convolutional neural network models pre-trained on ImageNet and fine-tuned on knee OA images. Furthermore, we argue that it is more appropriate to assess the accuracy of automatic knee OA severity predictions using a continuous distance-based evaluation metric like mean squared error than it is to use classification accuracy. This leads to the formulation of the prediction of KL grades as a regression problem and further improves accuracy. Results on a dataset of X-ray images and KL grades from the Osteoarthritis Initiative (OAI) show a sizable improvement over the current state-of-the-art.},
  eventtitle = {2016 23rd {{International Conference}} on {{Pattern Recognition}} ({{ICPR}})},
  isbn = {978-1-5090-4847-2},
  langid = {english},
  file = {C\:\\Users\\USER\\Zotero\\storage\\A5GTGPD5\\Antony et al. - 2016 - Quantifying radiographic knee osteoarthritis sever.pdf}
}

@inproceedings{azadbakhtMultiPathViTOCR2022,
  title = {{{MultiPath ViT OCR}}: {{A Lightweight Visual Transformer-based License Plate Optical Character Recognition}}},
  shorttitle = {{{MultiPath ViT OCR}}},
  booktitle = {2022 12th {{International Conference}} on {{Computer}} and {{Knowledge Engineering}} ({{ICCKE}})},
  author = {Azadbakht, Alireza and Kheradpisheh, Saeed Reza and Farahani, Hadi},
  date = {2022-11-17},
  pages = {092--095},
  publisher = {{IEEE}},
  location = {{Mashhad, Iran, Islamic Republic of}},
  doi = {10.1109/ICCKE57176.2022.9960026},
  url = {https://ieeexplore.ieee.org/document/9960026/},
  urldate = {2023-06-28},
  abstract = {Because of the natural conditions of license plate images, the Optical Character Recognition (OCR) of these images is generally a challenging problem. OCR systems are utilized in edge devices with limited computation power. Despite the considerable progress of deep neural networks, state-of-the-art models are not always an excellent solution to this problem. Most models have many parameters, and in practice, they need many resources to train, maintain and implement on edge devices. We propose a lightweight model based on Visual Transformer architecture and achieve competitive results against traditional CRNN models. Due to the lack of a rich and large-scale dataset for Persian license plates, we gathered and annotated 1.3M images of license plates in various natural conditions from different points of view and different cameras. We call this dataset as LicenseNet. Our proposed model achieves 77.25\% accuracy against CNN models with 75.18\% accuracy and embedded OCR models in cameras with 60.37\% accuracy on the LicenseNet test set. Furthermore, we achieved better accuracy with 3.21 times fewer training parameters than previously proposed models.},
  eventtitle = {2022 12th {{International Conference}} on {{Computer}} and {{Knowledge Engineering}} ({{ICCKE}})},
  isbn = {978-1-66547-613-3},
  langid = {english},
  file = {C\:\\Users\\USER\\Zotero\\storage\\ATUCJKDB\\Azadbakht et al. - 2022 - MultiPath ViT OCR A Lightweight Visual Transforme.pdf}
}

@incollection{baccoucheSequentialDeepLearning2011,
  title = {Sequential {{Deep Learning}} for {{Human Action Recognition}}},
  booktitle = {Human {{Behavior Unterstanding}}},
  author = {Baccouche, Moez and Mamalet, Franck and Wolf, Christian and Garcia, Christophe and Baskurt, Atilla},
  editor = {Salah, Albert Ali and Lepri, Bruno},
  editorb = {Hutchison, David and Kanade, Takeo and Kittler, Josef and Kleinberg, Jon M. and Mattern, Friedemann and Mitchell, John C. and Naor, Moni and Nierstrasz, Oscar and Pandu Rangan, C. and Steffen, Bernhard and Sudan, Madhu and Terzopoulos, Demetri and Tygar, Doug and Vardi, Moshe Y. and Weikum, Gerhard},
  editorbtype = {redactor},
  date = {2011},
  volume = {7065},
  pages = {29--39},
  publisher = {{Springer Berlin Heidelberg}},
  location = {{Berlin, Heidelberg}},
  doi = {10.1007/978-3-642-25446-8_4},
  url = {http://link.springer.com/10.1007/978-3-642-25446-8_4},
  urldate = {2022-05-08},
  abstract = {We propose in this paper a fully automated deep model, which learns to classify human actions without using any prior knowledge. The first step of our scheme, based on the extension of Convolutional Neural Networks to 3D, automatically learns spatio-temporal features. A Recurrent Neural Network is then trained to classify each sequence considering the temporal evolution of the learned features for each timestep. Experimental results on the KTH dataset show that the proposed approach outperforms existing deep models, and gives comparable results with the best related works.},
  isbn = {978-3-642-25445-1 978-3-642-25446-8},
  langid = {english},
  file = {C\:\\Users\\USER\\Zotero\\storage\\ZBPFK6FI\\Baccouche et al. - 2011 - Sequential Deep Learning for Human Action Recognit.pdf}
}

@inproceedings{bansalMicroActivityRecognition2018,
  title = {Micro {{Activity Recognition}} of {{Mobile Phone Users Using Inbuilt Sensors}}},
  booktitle = {2018 8th {{International Conference}} on {{Cloud Computing}}, {{Data Science}} \& {{Engineering}} ({{Confluence}})},
  author = {Bansal, Aakash and Shukla, Abhishek and Rastogi, Shaurya and Mittal, Sangeeta},
  date = {2018-01},
  pages = {225--230},
  publisher = {{IEEE}},
  location = {{Noida}},
  doi = {10.1109/CONFLUENCE.2018.8442663},
  url = {https://ieeexplore.ieee.org/document/8442663/},
  urldate = {2022-03-18},
  abstract = {Human Activity Recognition using smartphone sensors is an area of active research. Micro activities of locomotion are indicators of higher level activities and general wellbeing of a user. In this paper, an approach for detecting a set of most common micro activities has been proposed and implemented. Five micro activities of locomotion namely sitting, standing, running, staircase ascend and descend have been considered. A two level classification model has been implemented to recognize these activities from data of inbuilt sensors of smartphone held in any of the three common positions by the user. Recognition accuracy of proposed approach is better than results reported in literature for similar problem. For purpose of training and testing, datasets have been collected on three different users and an android app has been developed to recognize activities in real time.},
  eventtitle = {2018 8th {{International Conference}} on {{Cloud Computing}}, {{Data Science}} \& {{Engineering}} ({{Confluence}})},
  isbn = {978-1-5386-1719-9},
  langid = {english},
  file = {C\:\\Users\\USER\\Zotero\\storage\\RQ26RWQE\\Bansal et al. - 2018 - Micro Activity Recognition of Mobile Phone Users U.pdf}
}

@article{bantilanThemismlFairnessAwareMachine2018,
  title = {Themis-Ml: {{A Fairness-Aware Machine Learning Interface}} for {{End-To-End Discrimination Discovery}} and {{Mitigation}}},
  shorttitle = {Themis-Ml},
  author = {Bantilan, Niels},
  date = {2018-01-02},
  journaltitle = {Journal of Technology in Human Services},
  shortjournal = {Journal of Technology in Human Services},
  volume = {36},
  number = {1},
  pages = {15--30},
  issn = {1522-8835, 1522-8991},
  doi = {10.1080/15228835.2017.1416512},
  url = {https://www.tandfonline.com/doi/full/10.1080/15228835.2017.1416512},
  urldate = {2022-02-12},
  abstract = {As more industries integrate machine learning into socially sensitive decision processes like hiring, loan-approval, and parole-granting, we are at risk of perpetuating historical and contemporary socioeconomic disparities. This is a critical problem because on the one hand, organizations who use but do not understand the discriminatory potential of such systems will facilitate the widening of social disparities under the assumption that algorithms are categorically objective. On the other hand, the responsible use of machine learning can help us measure, understand, and mitigate the implicit historical biases in socially sensitive data by expressing implicit decision-making mental models in terms of explicit statistical models. In this article we specify, implement, and evaluate a “fairness-aware” machine learning interface called themis-ml, which is intended for use by individual data scientists and engineers, academic research teams, or larger product teams who use machine learning in production systems.},
  langid = {english},
  file = {C\:\\Users\\USER\\Zotero\\storage\\DUHMDYBD\\Bantilan - 2018 - Themis-ml A Fairness-Aware Machine Learning Inter.pdf}
}

@misc{barryCarrigtwohillParishHistory,
  title = {Carrigtwohill {{Parish History}}},
  author = {Barry, Tom},
  publisher = {{Carrigtwohillparish.ie}},
  url = {https://carrigtwohillparish.ie/history/parish-history/},
  urldate = {2022-03-06},
  abstract = {With the parish of Carrigtwohill in the throes of profound transformation from a largely agricultural district to substantial urbanisation, the opportunity to present a brief history is timely.}
}

@online{benabderrazakOpenCVEASTModel2020,
  title = {{{OpenCV EAST}} Model and {{Tesseract}} for Detection and Recognition of Text in Natural Scenes},
  author = {Benabderrazak, Jaafar},
  date = {2020-04-05},
  url = {https://jaafarbenabderrazak-info.medium.com/opencv-east-model-and-tesseract-for-detection-and-recognition-of-text-in-natural-scene-1fa48335c4d1},
  abstract = {Google has digitized books ang Google earth is using NLP to identify addresses, but how does it work exactly? Deep learning approaches like neural networks can be used to combine the tasks of localizing text (Text detection) in an image along with understanding what the text is (Text recognition).}
}

@online{bexMassiveTutorialImage2022,
  title = {Massive {{Tutorial}} on {{Image Processing And Preparation For Deep Learning}} in {{Python}}, \#1},
  author = {Bex, T.},
  date = {2022-02-17},
  url = {https://towardsdatascience.com/massive-tutorial-on-image-processing-and-preparation-for-deep-learning-in-python-1-e534ee42f122},
  urldate = {2022-05-25},
  abstract = {We are here on a sad business. Very sad, indeed. We are here to learn how to take beautiful, breathtaking images and turn them into a bunch of ugly little numbers so that they are more presentable to all those soulless, mindless machines. We will take animals and strip them of their color, making them black and white. Grab flowers with vivid colors and rob them of their beauty. We will look at disturbing images of XRays and see ways to make them even more disturbing. Sometimes, we might even have fun drawing coins using a computer algorithm. In other words, we will learn how to perform image processing. And our library of honor will be Scikit-Image (Skimage) throughout the article.}
}

@article{bhamraComparativeAnalysisMongoDB,
  title = {A {{Comparative Analysis}} of {{MongoDB}} and {{Cassandra}}},
  author = {Bhamra, Kavita},
  pages = {65},
  langid = {english},
  file = {C\:\\Users\\USER\\Zotero\\storage\\7IXD5FF3\\Bhamra - A Comparative Analysis of MongoDB and Cassandra.pdf}
}

@article{biroSynthetizedMultilanguageOCR2023,
  title = {Synthetized {{Multilanguage OCR Using CRNN}} and {{SVTR Models}} for {{Realtime Collaborative Tools}}},
  author = {Biró, Attila and Cuesta-Vargas, Antonio Ignacio and Martín-Martín, Jaime and Szilágyi, László and Szilágyi, Sándor Miklós},
  date = {2023-03-30},
  journaltitle = {Applied Sciences},
  shortjournal = {Applied Sciences},
  volume = {13},
  number = {7},
  pages = {4419},
  issn = {2076-3417},
  doi = {10.3390/app13074419},
  url = {https://www.mdpi.com/2076-3417/13/7/4419},
  urldate = {2023-06-28},
  abstract = {Background: Remote diagnosis using collaborative tools have led to multilingual joint working sessions in various domains, including comprehensive health care, and resulting in more inclusive health care services. One of the main challenges is providing a real-time solution for shared documents and presentations on display to improve the efficacy of noninvasive, safe, and farreaching collaborative models. Classic optical character recognition (OCR) solutions fail when there is a mixture of languages or dialects or in case of the participation of different technical levels and skills. Due to the risk of misunderstandings caused by mistranslations or lack of domain knowledge of the interpreters involved, the technological pipeline also needs artificial intelligence (AI)-supported improvements on the OCR side. This study examines the feasibility of machine learning-supported OCR in a multilingual environment. The novelty of our method is that it provides a solution not only for different speaking languages but also for a mixture of technological languages, using artificially created vocabulary and a custom training data generation approach. Methods: A novel hybrid language vocabulary creation method is utilized in the OCR training process in combination with convolutional recurrent neural networks (CRNNs) and a single visual model for scene text recognition within the patch-wise image tokenization framework (SVTR). Data: In the research, we used a dedicated Python-based data generator built on dedicated collaborative tool-based templates to cover and simulated the real-life variances of remote diagnosis and co-working collaborative sessions with high accuracy. The generated training datasets ranged from 66 k to 8.5 M in size. Twenty-one research results were analyzed. Instruments: Training was conducted by using tuned PaddleOCR with CRNN and SVTR modeling and a domain-specific, customized vocabulary. The Weight \& Biases (WANDB) machine learning (ML) platform is used for experiment tracking, dataset versioning, and model evaluation. Based on the evaluations, the training dataset was adjusted by using a different language corpus or/and modifications applied to templates. Results: The machine learning models recognized the multilanguage/hybrid texts with high accuracy. The highest precision scores achieved are 90.25\%, 91.35\%, and 93.89\%. Conclusions: machine learning models for special multilanguages, including languages with artificially made vocabulary, perform consistently with high accuracy.},
  langid = {english},
  file = {C\:\\Users\\USER\\Zotero\\storage\\Q6DZZN2F\\Biró et al. - 2023 - Synthetized Multilanguage OCR Using CRNN and SVTR .pdf}
}

@article{boiangiuVOTINGBASEDOCRSYSTEM,
  title = {{{VOTING-BASED OCR SYSTEM}}},
  author = {Boiangiu, Costin-Anton and Ioanitescu, Radu and Dragomir, Razvan-Costin},
  pages = {18},
  abstract = {Current solutions for performing Optical Character Recognition (OCR) in both academic and commercial environments have good recognition capabilities but each one of them has limitations as a consequence of the assumptions made for the defining algorithmic approach. This paper aims to define a new OCR method that combines the results from different algorithms and/or engines. Because we know in advance the specific characteristics of each OCR approach in a given context, a voting algorithm can be applied between their results. The final result of the proposed method is a combination of the different algorithms and exhibits better characteristics than any individual version taken separately. Furthermore, we propose a fully integrated solution containing voting-based approaches for all the preprocessing stages necessary in a complete OCR solution: image binarization, image segmentation, and layout analyze.},
  langid = {english},
  file = {C\:\\Users\\USER\\Zotero\\storage\\HVM2L9MD\\Boiangiu et al. - VOTING-BASED OCR SYSTEM.pdf}
}

@article{brahimDecisionSupportTool2019,
  title = {A Decision Support Tool for Early Detection of Knee {{OsteoArthritis}} Using {{X-ray}} Imaging and Machine Learning: {{Data}} from the {{OsteoArthritis Initiative}}},
  shorttitle = {A Decision Support Tool for Early Detection of Knee {{OsteoArthritis}} Using {{X-ray}} Imaging and Machine Learning},
  author = {Brahim, Abdelbasset and Jennane, Rachid and Riad, Rabia and Janvier, Thomas and Khedher, Laila and Toumi, Hechmi and Lespessailles, Eric},
  date = {2019-04},
  journaltitle = {Computerized Medical Imaging and Graphics},
  shortjournal = {Computerized Medical Imaging and Graphics},
  volume = {73},
  pages = {11--18},
  issn = {08956111},
  doi = {10.1016/j.compmedimag.2019.01.007},
  url = {https://linkinghub.elsevier.com/retrieve/pii/S0895611119300035},
  urldate = {2022-04-02},
  langid = {english},
  file = {C\:\\Users\\USER\\Zotero\\storage\\9PHNMP4H\\Brahim et al. - 2019 - A decision support tool for early detection of kne.pdf}
}

@inproceedings{breuelHighPerformanceOCRPrinted2013,
  title = {High-{{Performance OCR}} for {{Printed English}} and {{Fraktur Using LSTM Networks}}},
  booktitle = {2013 12th {{International Conference}} on {{Document Analysis}} and {{Recognition}}},
  author = {Breuel, Thomas M. and Ul-Hasan, Adnan and Al-Azawi, Mayce Ali and Shafait, Faisal},
  date = {2013-08},
  pages = {683--687},
  publisher = {{IEEE}},
  location = {{Washington, DC, USA}},
  doi = {10.1109/ICDAR.2013.140},
  url = {http://ieeexplore.ieee.org/document/6628705/},
  urldate = {2023-07-09},
  abstract = {Long Short-Term Memory (LSTM) networks have yielded excellent results on handwriting recognition. This paper describes an application of bidirectional LSTM networks to the problem of machine-printed Latin and Fraktur recognition. Latin and Fraktur recognition differs significantly from handwriting recognition in both the statistical properties of the data, as well as in the required, much higher levels of accuracy. Applications of LSTM networks to handwriting recognition use two-dimensional recurrent networks, since the exact position and baseline of handwritten characters is variable. In contrast, for printed OCR, we used a one-dimensional recurrent network combined with a novel algorithm for baseline and x-height normalization. A number of databases were used for training and testing, including the UW3 database, artificially generated and degraded Fraktur text and scanned pages from a book digitization project. The LSTM architecture achieved 0.6\% character-level test-set error on English text. When the artificially degraded Fraktur data set is divided into training and test sets, the system achieves an error rate of 1.64\%. On specific books printed in Fraktur (not part of the training set), the system achieves error rates of 0.15\% (Fontane) and 1.47\% (Ersch-Gruber). These recognition accuracies were found without using any language modelling or any other post-processing techniques.},
  eventtitle = {2013 12th {{International Conference}} on {{Document Analysis}} and {{Recognition}} ({{ICDAR}})},
  isbn = {978-0-7695-4999-6},
  langid = {english},
  file = {C\:\\Users\\USER\\Zotero\\storage\\3LTIEQYI\\Breuel et al. - 2013 - High-Performance OCR for Printed English and Frakt.pdf}
}

@article{c.kellyRepresentativeSampleVs,
  title = {Representative {{Sample}} vs. {{Random Sample}}: {{What}}'s the {{Difference}}?},
  author = {C. Kelly, Robert},
  journaltitle = {Investopedia},
  url = {https://www.investopedia.com/ask/answers/042915/whats-difference-between-representative-sample-and-random-sample.asp},
  urldate = {2022-02-12},
  abstract = {Representative Sample vs. Random Sample: An Overview When conducting statistical analyses, economists and researchers seek to reduce sampling bias to a near negligible level. The danger of sampling bias is that it can result in a biased sample of a population (or non-human factors) in which all individuals, or instances, were not equally likely to have been selected.}
}

@inproceedings{cakicDigitalTransformationTransparency2021,
  title = {Digital {{Transformation}} and {{Transparency}} in {{Wine Supply Chain Using OCR}} and {{DLT}}},
  booktitle = {2021 25th {{International Conference}} on {{Information Technology}} ({{IT}})},
  author = {Cakic, Stevan and Ismailisufi, Aida and Popovic, Tomo and Krco, Srdjan and Gligoric, Nenad and Kupresanin, Srdjan and Maras, Vesna},
  date = {2021-02-16},
  pages = {1--5},
  publisher = {{IEEE}},
  location = {{Zabljak, Montenegro}},
  doi = {10.1109/IT51528.2021.9390117},
  url = {https://ieeexplore.ieee.org/document/9390117/},
  urldate = {2023-06-26},
  abstract = {This paper describes an effort to utilize IoT, OCR, and blockchain technology to create wine track and trace system evaluated in a real-life environment. The research is focused on digital transformation in traditional wine supply chain, using computer vision to read the existing serial numbers labeled on bottles, so as to uniquely identifying individual bottles of wine and track the item life-cycle. The system provides mobile app to allow end consumers to scan each wine bottle and learn more about that particular product instance, its origin, authenticity, rating and potentially other characteristics. Status of each bottle is updated every time it has been scanned. To ensure the transparency of the recorded data and information immutability, the blockchain technology is used to record all relevant information into the ledger, e.g. all status updates for each item. The developed service enables tracking of a bottle throughout the supply chain, from a producer to a consumer, where traceability story is still not finalized. The consumed serial numbers are kept in the ledger, to avoid counterfeit scenario when one “bottle” (i.e. one serial number) is being sold multiple times. The life-cycle of bottle and its status changes are recorded, and the authenticity ensured facilitating verifiable identity of the authorized handlers and cutting edge cryptography, thus providing additional trust in the solution and transparency to all stakeholders.},
  eventtitle = {2021 25th {{International Conference}} on {{Information Technology}} ({{IT}})},
  isbn = {978-1-72819-103-4},
  langid = {english},
  file = {C\:\\Users\\USER\\Zotero\\storage\\NTPLAPHD\\Cakic et al. - 2021 - Digital Transformation and Transparency in Wine Su.pdf}
}

@inproceedings{cakicUseTesseractOCR2020,
  title = {The {{Use}} of {{Tesseract OCR Number Recognition}} for {{Food Tracking}} and {{Tracing}}},
  booktitle = {2020 24th {{International Conference}} on {{Information Technology}} ({{IT}})},
  author = {Cakic, Stevan and Popovic, Tomo and Sandi, Stevan and Krco, Srdan and Gazivoda, Anita},
  date = {2020-02},
  pages = {1--4},
  publisher = {{IEEE}},
  location = {{Zabljak, Montenegro}},
  doi = {10.1109/IT48810.2020.9070558},
  url = {https://ieeexplore.ieee.org/document/9070558/},
  urldate = {2023-06-22},
  abstract = {One of the most interesting enabling technologies for digital transformation is computer vision. Object and character recognition has already become very popular and it is used in everyday life. This research focuses on the use of computer vision to read serial numbers from wine labels in order to enable applications based on tracking and tracing of each individual wine bottle. After experimenting with several OCR tools, an open source software called Tesseract OCR engine was selected for the pilot solution. The paper discusses the implementation and image processioning that improved detection accuracy. The coding was done in the Python programming language. The solution code was tested using real-life like images of wine serial numbers. In addition, a custom built web-based evaluation tool was created and used for the interactive evaluation of the system.},
  eventtitle = {2020 24th {{International Conference}} on {{Information Technology}} ({{IT}})},
  isbn = {978-1-72815-136-6},
  langid = {english},
  file = {C\:\\Users\\USER\\Zotero\\storage\\55HZTC3M\\Cakic et al. - 2020 - The Use of Tesseract OCR Number Recognition for Fo.pdf}
}

@article{changStepStepImplementation,
  title = {Step by {{Step Implementation}}: {{3D Convolutional Neural Network}} in {{Keras}}},
  author = {Chang, Michael},
  url = {https://towardsdatascience.com/step-by-step-implementation-3d-convolutional-neural-network-in-keras-12efbdd7b130},
  abstract = {In this article, we will be briefly explaining what a 3d CNN is, and how it is different from a generic 2d CNN. Then we will teach you step by step how to implement your own 3D Convolutional Neural Network using Keras.}
}

@inproceedings{chauhanConvolutionalNeuralNetwork2018,
  title = {Convolutional {{Neural Network}} ({{CNN}}) for {{Image Detection}} and {{Recognition}}},
  booktitle = {2018 {{First International Conference}} on {{Secure Cyber Computing}} and {{Communication}} ({{ICSCCC}})},
  author = {Chauhan, Rahul and Ghanshala, Kamal Kumar and Joshi, R.C},
  date = {2018-12},
  pages = {278--282},
  publisher = {{IEEE}},
  location = {{Jalandhar, India}},
  doi = {10.1109/ICSCCC.2018.8703316},
  url = {https://ieeexplore.ieee.org/document/8703316/},
  urldate = {2022-06-02},
  abstract = {Deep Learning algorithms are designed in such a way that they mimic the function of the human cerebral cortex. These algorithms are representations of deep neural networks i.e. neural networks with many hidden layers. Convolutional neural networks are deep learning algorithms that can train large datasets with millions of parameters, in form of 2D images as input and convolve it with filters to produce the desired outputs. In this article, CNN models are built to evaluate its performance on image recognition and detection datasets. The algorithm is implemented on MNIST and CIFAR-10 dataset and its performance are evaluated. The accuracy of models on MNIST is 99.6 \%, CIFAR-10 is using real-time data augmentation and dropout on CPU unit.},
  eventtitle = {2018 {{First International Conference}} on {{Secure Cyber Computing}} and {{Communication}} ({{ICSCCC}})},
  isbn = {978-1-5386-6373-8},
  langid = {english},
  file = {C\:\\Users\\USER\\Zotero\\storage\\NS3G24IN\\Chauhan et al. - 2018 - Convolutional Neural Network (CNN) for Image Detec.pdf}
}

@article{choWhatKindsSensors2020,
  title = {What {{Kinds}} of {{Sensors}} Are {{Embedded}} in {{Smartphones}}?},
  author = {Cho, Andy},
  date = {2020-12-29},
  journaltitle = {SamgsungSDS},
  url = {https://www.samsungsds.com/en/story/What-Kinds-of-Sensors-are-Embedded-in-Smartphones.html}
}

@article{christodoulouSystematicReviewShows2019,
  title = {A Systematic Review Shows No Performance Benefit of Machine Learning over Logistic Regression for Clinical Prediction Models},
  author = {Christodoulou, Evangelia and Ma, Jie and Collins, Gary S. and Steyerberg, Ewout W. and Verbakel, Jan Y. and Van Calster, Ben},
  date = {2019-06},
  journaltitle = {Journal of Clinical Epidemiology},
  shortjournal = {Journal of Clinical Epidemiology},
  volume = {110},
  pages = {12--22},
  issn = {08954356},
  doi = {10.1016/j.jclinepi.2019.02.004},
  url = {https://linkinghub.elsevier.com/retrieve/pii/S0895435618310813},
  urldate = {2022-02-12},
  abstract = {Objectives: The objective of this study was to compare performance of logistic regression (LR) with machine learning (ML) for clinical prediction modeling in the literature. Study Design and Setting: We conducted a Medline literature search (1/2016 to 8/2017) and extracted comparisons between LR and ML models for binary outcomes. Results: We included 71 of 927 studies. The median sample size was 1,250 (range 72e3,994,872), with 19 predictors considered (range 5e563) and eight events per predictor (range 0.3e6,697). The most common ML methods were classification trees, random forests, artificial neural networks, and support vector machines. In 48 (68\%) studies, we observed potential bias in the validation procedures. Sixty-four (90\%) studies used the area under the receiver operating characteristic curve (AUC) to assess discrimination. Calibration was not addressed in 56 (79\%) studies. We identified 282 comparisons between an LR and ML model (AUC range, 0.52e0.99). For 145 comparisons at low risk of bias, the difference in logit(AUC) between LR and ML was 0.00 (95\% confidence interval, À0.18 to 0.18). For 137 comparisons at high risk of bias, logit(AUC) was 0.34 (0.20e0.47) higher for ML. Conclusion: We found no evidence of superior performance of ML over LR. Improvements in methodology and reporting are needed for studies that compare modeling algorithms. Ó 2019 Elsevier Inc. All rights reserved.},
  langid = {english},
  file = {C\:\\Users\\USER\\Zotero\\storage\\ZDCB9GP8\\Christodoulou et al. - 2019 - A systematic review shows no performance benefit o.pdf}
}

@article{councilCarrigtwohillCommunity,
  title = {Carrigtwohill {{Community}}},
  author = {Council, Community},
  journaltitle = {carrigtwohillcommunity.ie},
  url = {http://carrigtwohillcommunity.ie/history/#:~:text=The%20Name%20Carrigtwohill&text=Tradition%20is%20current%20that%20a,of%20Irish%20Life%E2%80%9D%20by%20W.R.},
  urldate = {2022-03-06}
}

@article{cowanMAORITATTOOINGSURVIVALS1921,
  title = {{{MAORI TATTOOING SURVIVALS}}. {{SOME NOTES ON MOKO}}},
  author = {Cowan, James},
  date = {1921},
  journaltitle = {The Journal of the Polynesian Society},
  volume = {30},
  eprint = {20701843},
  eprinttype = {jstor},
  pages = {241--245},
  url = {http://www.jstor.org/stable/20701843},
  issue = {4(120)},
  langid = {english},
  file = {C\:\\Users\\USER\\Zotero\\storage\\XGLGI3VZ\\Cowan - 1921 - MAORI TATTOOING SURVIVALS. SOME NOTES ON MOKO.pdf}
}

@article{DescriptiveInferentialStatistics,
  title = {Descriptive and {{Inferential Statistics}}},
  journaltitle = {Laerd Statistics},
  url = {https://statistics.laerd.com/statistical-guides/descriptive-inferential-statistics.php},
  urldate = {2022-02-11},
  abstract = {When analysing data, such as the marks achieved by 100 students for a piece of coursework, it is possible to use both descriptive and inferential statistics in your analysis of their marks. Typically, in most research conducted on groups of people, you will use both descriptive and inferential statistics to analyse your results and draw conclusions. So what are descriptive and inferential statistics? And what are their differences?}
}

@article{doushNovelArabicOCR2018,
  title = {A Novel {{Arabic OCR}} Post-Processing Using Rule-Based and Word Context Techniques},
  author = {Doush, Iyad Abu and Alkhateeb, Faisal and Gharaibeh, Anwaar Hamdi},
  date = {2018-06},
  journaltitle = {International Journal on Document Analysis and Recognition (IJDAR)},
  shortjournal = {IJDAR},
  volume = {21},
  number = {1-2},
  pages = {77--89},
  issn = {1433-2833, 1433-2825},
  doi = {10.1007/s10032-018-0297-y},
  url = {http://link.springer.com/10.1007/s10032-018-0297-y},
  urldate = {2023-07-14},
  abstract = {Optical character recognition (OCR) is the process of recognizing characters automatically from scanned documents for editing, indexing, searching, and reducing the storage space. The resulted text from the OCR usually does not match the text in the original document. In order to minimize the number of incorrect words in the obtained text, OCR post-processing approaches can be used. Correcting OCR errors is more complicated when we are dealing with the Arabic language because of its complexity such as connected letters, different letters may have the same shape, and the same letter may have different forms. This paper provides a statistical Arabic language model and post-processing techniques based on hybridizing the error model approach with the context approach. The proposed model is language independent and non-constrained with the string length. To the best of our knowledge, this is the first end-to-end OCR post-processing model that is applied to the Arabic language. In order to train the proposed model, we build Arabic OCR context database which contains 9000 images of Arabic text. Also, the evaluation of the OCR post-processing system results is automated using our novel alignment technique which is called fast automatic hashing text alignment. Our experimental results show that the rule-based system improves the word error rate from 24.02\% to become 20.26\% by using a training data set of 1000 images. On the other hand, after this training, we apply the rule-based system on 500 images as a testing dataset and the word error rate is improved from 14.95\% to become 14.53\%. The proposed hybrid OCR post-processing system improves the results based on using 1000 training images from a word error rate of 24.02\% to become 18.96\%. After training the hybrid system, we used 500 images for testing and the results show that the word error rate enhanced from 14.95 to become 14.42. The obtained results show that the proposed hybrid system outperforms the rule-based system.},
  langid = {english},
  file = {C\:\\Users\\USER\\Zotero\\storage\\6KTE35ZS\\Doush et al. - 2018 - A novel Arabic OCR post-processing using rule-base.pdf}
}

@article{dr.marilynsimonAssumptionsLimitationsDelimitations2011,
  title = {Assumptions, {{Limitations}} and {{Delimitations}}},
  author = {Dr. Marilyn Simon},
  date = {2011},
  journaltitle = {www.dissertationrecipes.com},
  url = {https://studylib.net/doc/8312011/assumptions---limitations-and-delimitations},
  urldate = {2022-02-13},
  abstract = {www.dissertationrecipes.comIt can be humbling and empowering at the same time to realize you are critically restricted in many ways when conducting scholarly research. These deficiencies include the availability of resources and even your own reasoning processes and human failings. The empowerment comes from recognizing your own shortcomings and the shortcomings of the choices you make, and then adjusting the best way possible. There is often some confusion regarding what are considered assumptions, limitations, and delimitations in conducting research.  As a public service, this will now be clarified}
}

@article{dunnewijkBriefHistoryMobile2007,
  title = {A Brief History of Mobile Communication in {{Europe}}},
  author = {Dunnewijk, Theo and Hultén, Staffan},
  date = {2007-08},
  journaltitle = {Telematics and Informatics},
  shortjournal = {Telematics and Informatics},
  volume = {24},
  number = {3},
  pages = {164--179},
  issn = {07365853},
  doi = {10.1016/j.tele.2007.01.013},
  url = {https://linkinghub.elsevier.com/retrieve/pii/S0736585307000226},
  urldate = {2022-03-19},
  abstract = {Since the introduction of mobile telephony in the early 1950s in Europe, US and Japan the demand for this service exploded. It seems that the latent demand for mobile telecommunication services for decade’s continued to be very strong. After the introduction of cellular technology the capacity of the services became able to meet the massive demand. Next and future generations of mobile telecommunication technologies bring increased transmission speed and more versatile services. This forces network operators to organise multi sourced information flows supplied by service providers to increase the network effect of the system instead of providing the network infrastructure and leave the content to the users as in pure voice telephony. The drivers and inhibitors behind the emergence and recent developments of mobile telecommunications systems in Europe, are highlighted in this paper. Liberalisation of the telecom markets in Europe drove new entrants to the market and curbed excessive pricing. However, in recent years the lack of challenging service is the main cause for the wavering development of newer generations of mobile telecommunication services.},
  langid = {english},
  file = {C\:\\Users\\USER\\Zotero\\storage\\PTGKMFLU\\Dunnewijk and Hultén - 2007 - A brief history of mobile communication in Europe.pdf}
}

@inproceedings{elrefaeiAutomaticElectricityMeter2015,
  title = {Automatic Electricity Meter Reading Based on Image Processing},
  booktitle = {2015 {{IEEE Jordan Conference}} on {{Applied Electrical Engineering}} and {{Computing Technologies}} ({{AEECT}})},
  author = {Elrefaei, Lamiaa A. and Bajaber, Asrar and Natheir, Sumayyah and AbuSanab, Nada and Bazi, Marwa},
  date = {2015-11},
  pages = {1--5},
  publisher = {{IEEE}},
  location = {{Amman, Jordan}},
  doi = {10.1109/AEECT.2015.7360571},
  url = {http://ieeexplore.ieee.org/document/7360571/},
  urldate = {2022-09-06},
  abstract = {This paper introduces a system based on image processing to obtain efficiently and accurately reading of the electricity digital meter. In this system the back camera of the mobile phones is used to acquire the image of the electricity meter. The system then applies a sequence of image processing functions to automatically extract and recognize the digits of the meter reading image. This image goes through three main stages: preprocessing which ends up with cropping the numeric reading area, segmentation of individual digits using horizontal and vertical scanning of the cropped numeric area, and recognition of the reading by comparing each segmented digit with the digits templates. The proposed system is implemented using Android Studio software with openCV library and has been tested on 21 images of electric meters captured by Smartphone camera in Saudi Arabia, and results shows a recognition with the accuracy rate of 96,49\% (per number digit) and 85.71\% accuracy rate for the electricity meter readings. The proposed system will be used in the future to develop a mobile application that could be used by the electricity company employees to facilitate the reading process.},
  eventtitle = {2015 {{IEEE Jordan Conference}} on {{Applied Electrical Engineering}} and {{Computing Technologies}} ({{AEECT}})},
  isbn = {978-1-4799-7442-9 978-1-4799-7431-3},
  langid = {english},
  file = {C\:\\Users\\USER\\Zotero\\storage\\NEKW6WKS\\Elrefaei et al. - 2015 - Automatic electricity meter reading based on image.pdf}
}

@online{eremenkoMachineLearningAZ,
  title = {Machine {{Learning A-Z}}™: {{Hands-On Python}} \& {{R In Data Science}}},
  author = {Eremenko, Kirill},
  url = {https://www.udemy.com/course/machinelearning/learn/lecture/6761146?start=0#questions},
  abstract = {Not so long ago Hadelin and I did an interview on the SDS Podcast. This is the best place to start if you would like to learn more about his background... and a bit about me too if this is your first course with me :)}
}

@inproceedings{fangRawMaterialForm2021,
  title = {Raw Material Form Recognition Based on {{Tesseract-OCR}}},
  booktitle = {2021 {{IEEE Conference}} on {{Telecommunications}}, {{Optics}} and {{Computer Science}} ({{TOCS}})},
  author = {Fang, Haodong and Bao, Min},
  date = {2021-12-10},
  pages = {942--945},
  publisher = {{IEEE}},
  location = {{Shenyang, China}},
  doi = {10.1109/TOCS53301.2021.9688701},
  url = {https://ieeexplore.ieee.org/document/9688701/},
  urldate = {2022-09-09},
  abstract = {For bearing companies, there are still many handwritten forms in the inspection of raw materials at present, and raw material data is also related to the traceability of finished products, which will inevitably affect the progress of the entire production process and product quality. Based on OCR technology and Tesseract-OCR character recognition foundation, this paper designs a set of raw material inspection form intelligent recognition and matching system. After performing denoising and binarization preprocessing on the form uploaded after manual inspection, the structure of the form is extracted and stored after character recognition processing, which can effectively improve work efficiency and reduce the error rate. The experimental results show that this experiment has a good result in the realization of electronic operation of the raw material form.},
  eventtitle = {2021 {{IEEE Conference}} on {{Telecommunications}}, {{Optics}} and {{Computer Science}} ({{TOCS}})},
  isbn = {978-1-66542-498-1},
  langid = {english},
  file = {C\:\\Users\\USER\\Zotero\\storage\\5BRBRZ2E\\Fang and Bao - 2021 - Raw material form recognition based on Tesseract-O.pdf}
}

@inproceedings{fengPortContainerNumber2020,
  title = {Port {{Container Number Recognition System Based}} on {{Improved YOLO}} and {{CRNN Algorithm}}},
  booktitle = {2020 {{International Conference}} on {{Artificial Intelligence}} and {{Electromechanical Automation}} ({{AIEA}})},
  author = {Feng, XingQi and Wang, ZhiWei and Liu, TongCai},
  date = {2020-06},
  pages = {72--77},
  publisher = {{IEEE}},
  location = {{Tianjin, China}},
  doi = {10.1109/AIEA51086.2020.00022},
  url = {https://ieeexplore.ieee.org/document/9221498/},
  urldate = {2023-06-28},
  eventtitle = {2020 {{International Conference}} on {{Artificial Intelligence}} and {{Electromechanical Automation}} ({{AIEA}})},
  isbn = {978-1-72818-288-9},
  file = {C\:\\Users\\USER\\Zotero\\storage\\JMTMF259\\Feng et al. - 2020 - Port Container Number Recognition System Based on .pdf}
}

@article{FordGoBikeBike,
  title = {Ford {{GoBike Bike Share System Passes Growth Milestones}}},
  journaltitle = {Ford GoBike},
  url = {https://web.archive.org/web/20180617015310/https://www.fordgobike.com/blog/ford-gobike-passes-growth-milestones},
  abstract = {SAN FRANCISCO (January 11, 2018) - The Ford GoBike program surpassed a key milestone in late December, with more than 500,000 rides taken since launch in June 2017. In another milestone, the number of Bay Area residents who have signed up for discounted memberships has nearly tripled since September 2017, thanks to vigorous efforts to inform low-income communities about the Bike Share for All discount program.}
}

@inproceedings{gencNumberRecognitionParts2018,
  title = {Number {{Recognition}} of {{Parts Book Schematics}} Using {{Convolutional Recurrent Neural Network}}},
  booktitle = {2018 {{International Conference}} on {{Information}} and {{Communication Technology Robotics}} ({{ICT-ROBOT}})},
  author = {Genc, Erdal and Shin, Hee Ran and Sik Park, Jang and Song, Jong-Kwan},
  date = {2018-09},
  pages = {1--3},
  publisher = {{IEEE}},
  location = {{Busan}},
  doi = {10.1109/ICT-ROBOT.2018.8549859},
  url = {https://ieeexplore.ieee.org/document/8549859/},
  urldate = {2023-06-28},
  abstract = {OCR (Optical Character Recognition) has been becoming a vital method to recognize digits, letters, symbols and so on. The main idea is basically the conversion of data files which consists of handwritten or machine-written digits or characters into a type to let the machine make edits and read. This way, it lets computers read articles or books. They can also read images and make the conversion to a text file by using OCR. There are two important benefits of OCR. First, is the enhancement of the device to operate more productively even if the number of employees is decreased. Secondly, is the increase in the efficiency of the storage. This paper compares two state-of-the-art OCR algorithms in a simulated environment by using modified dataset. Simulation results are shown in part 4.},
  eventtitle = {2018 {{International Conference}} on {{Information}} and {{Communication Technology Robotics}} ({{ICT-ROBOT}})},
  isbn = {978-1-72811-996-0},
  langid = {english},
  file = {C\:\\Users\\USER\\Zotero\\storage\\KCXH86DN\\Genc et al. - 2018 - Number Recognition of Parts Book Schematics using .pdf}
}

@inproceedings{ghoshLowCostData2014,
  title = {A Low Cost Data Acquisition System from Digital Display Instruments Employing Image Processing Technique},
  booktitle = {2014 {{International Conference}} on {{Advances}} in {{Computing}}, {{Communications}} and {{Informatics}} ({{ICACCI}})},
  author = {Ghosh, Soumyadip and Shit, Suprosanna},
  date = {2014-09},
  pages = {1065--1068},
  publisher = {{IEEE}},
  location = {{Delhi, India}},
  doi = {10.1109/ICACCI.2014.6968229},
  url = {http://ieeexplore.ieee.org/document/6968229/},
  urldate = {2022-10-04},
  abstract = {The use of digital instruments in industries and laboratories is rapidly increasing as they are simple to calibrate and have relatively high precision. In this paper, an automatic data acquisition system is proposed using OCR technique from digital multi-meter and other similar digital display devices. The input image is taken from a digital multi-meter having LCD seven segment display using a webcam. The image is then processed to extract numeric digits which are recognized using a feedforward neural network. The recognized values may be then exported to a spreadsheet for graph plotting and further analysis. A distinct advantage of this method is that it can automatically detect decimal point as well as negative sign. This setup can be used in real time systems employing a wide variety of digital display instruments, with high accuracy.},
  eventtitle = {2014 {{International Conference}} on {{Advances}} in {{Computing}}, {{Communications}} and {{Informatics}} ({{ICACCI}})},
  isbn = {978-1-4799-3080-7 978-1-4799-3078-4},
  langid = {english},
  file = {C\:\\Users\\USER\\Zotero\\storage\\5YC8WAE4\\Ghosh and Shit - 2014 - A low cost data acquisition system from digital di.pdf}
}

@inproceedings{ghoshLowCostData2014a,
  title = {A Low Cost Data Acquisition System from Digital Display Instruments Employing Image Processing Technique},
  booktitle = {2014 {{International Conference}} on {{Advances}} in {{Computing}}, {{Communications}} and {{Informatics}} ({{ICACCI}})},
  author = {Ghosh, Soumyadip and Shit, Suprosanna},
  date = {2014-09},
  pages = {1065--1068},
  publisher = {{IEEE}},
  location = {{Delhi, India}},
  doi = {10.1109/ICACCI.2014.6968229},
  url = {http://ieeexplore.ieee.org/document/6968229/},
  urldate = {2022-10-05},
  abstract = {The use of digital instruments in industries and laboratories is rapidly increasing as they are simple to calibrate and have relatively high precision. In this paper, an automatic data acquisition system is proposed using OCR technique from digital multi-meter and other similar digital display devices. The input image is taken from a digital multi-meter having LCD seven segment display using a webcam. The image is then processed to extract numeric digits which are recognized using a feedforward neural network. The recognized values may be then exported to a spreadsheet for graph plotting and further analysis. A distinct advantage of this method is that it can automatically detect decimal point as well as negative sign. This setup can be used in real time systems employing a wide variety of digital display instruments, with high accuracy.},
  eventtitle = {2014 {{International Conference}} on {{Advances}} in {{Computing}}, {{Communications}} and {{Informatics}} ({{ICACCI}})},
  isbn = {978-1-4799-3080-7 978-1-4799-3078-4},
  langid = {english},
  file = {C\:\\Users\\USER\\Zotero\\storage\\IJK7VNPS\\Ghosh and Shit - 2014 - A low cost data acquisition system from digital di.pdf}
}

@article{goodfellowGenerativeAdversarialNets,
  title = {Generative {{Adversarial Nets}}},
  author = {Goodfellow, Ian and Pouget-Abadie, Jean and Mirza, Mehdi and Xu, Bing and Warde-Farley, David and Ozair, Sherjil and Courville, Aaron and Bengio, Yoshua},
  pages = {9},
  langid = {english},
  file = {C\:\\Users\\USER\\Zotero\\storage\\K279E46R\\Goodfellow et al. - Generative Adversarial Nets.pdf}
}

@online{goodfellowGenerativeAdversarialNetworks2014,
  title = {Generative {{Adversarial Networks}}},
  author = {Goodfellow, Ian J. and Pouget-Abadie, Jean and Mirza, Mehdi and Xu, Bing and Warde-Farley, David and Ozair, Sherjil and Courville, Aaron and Bengio, Yoshua},
  date = {2014-06-10},
  eprint = {1406.2661},
  eprinttype = {arxiv},
  eprintclass = {cs, stat},
  url = {http://arxiv.org/abs/1406.2661},
  urldate = {2022-05-29},
  abstract = {We propose a new framework for estimating generative models via an adversarial process, in which we simultaneously train two models: a generative model G that captures the data distribution, and a discriminative model D that estimates the probability that a sample came from the training data rather than G. The training procedure for G is to maximize the probability of D making a mistake. This framework corresponds to a minimax two-player game. In the space of arbitrary functions G and D, a unique solution exists, with G recovering the training data distribution and D equal to 1/2 everywhere. In the case where G and D are defined by multilayer perceptrons, the entire system can be trained with backpropagation. There is no need for any Markov chains or unrolled approximate inference networks during either training or generation of samples. Experiments demonstrate the potential of the framework through qualitative and quantitative evaluation of the generated samples.},
  langid = {english},
  pubstate = {preprint},
  keywords = {Computer Science - Machine Learning,Statistics - Machine Learning},
  file = {C\:\\Users\\USER\\Zotero\\storage\\W64H9CK6\\Goodfellow et al. - 2014 - Generative Adversarial Networks.pdf}
}

@book{graupePrinciplesArtificialNeural2013,
  title = {Principles of Artificial Neural Networks},
  author = {Graupe, Daniel},
  date = {2013},
  series = {Advanced Series on Circuits and Systems},
  edition = {3rd edition},
  number = {volume 7},
  publisher = {{World Scientific}},
  location = {{New Jersey}},
  isbn = {978-981-4522-73-1},
  langid = {english},
  pagetotal = {363},
  keywords = {Neural networks (Computer science)},
  file = {C\:\\Users\\USER\\Zotero\\storage\\U84VHE62\\Graupe - 2013 - Principles of artificial neural networks.pdf}
}

@online{guptaHumanActivityRecognition,
  title = {Human {{Activity Recognition Dataset}} ({{OpenPose}})},
  author = {family=GUPTA, given=PASHUPATI, given-i=PASHUPATI},
  url = {https://www.kaggle.com/datasets/pashupatigupta/human-keypoints-tracking-dataset},
  abstract = {The motivation behind creating and uploading this dataset is to be able to predict human activities accurately using OpenPose and an ML/DL model. The dataset is generated by running OpenPose on subjects performing different activities (stand, walk, squat, jump) in a video. OpenPose gives the coordinates of crucial human key points (nosex, nosey, Relbowx, Relbowy, etc.) that can work as an input for an activity recognition model},
  organization = {{Kaggle}}
}

@article{haiboheLearningImbalancedData2009,
  title = {Learning from {{Imbalanced Data}}},
  author = {{Haibo He} and Garcia, E.A.},
  date = {2009-09},
  journaltitle = {IEEE Transactions on Knowledge and Data Engineering},
  shortjournal = {IEEE Trans. Knowl. Data Eng.},
  volume = {21},
  number = {9},
  pages = {1263--1284},
  issn = {1041-4347},
  doi = {10.1109/TKDE.2008.239},
  url = {http://ieeexplore.ieee.org/document/5128907/},
  urldate = {2022-02-12},
  abstract = {With the continuous expansion of data availability in many large-scale, complex, and networked systems, such as surveillance, security, Internet, and finance, it becomes critical to advance the fundamental understanding of knowledge discovery and analysis from raw data to support decision-making processes. Although existing knowledge discovery and data engineering techniques have shown great success in many real-world applications, the problem of learning from imbalanced data (the imbalanced learning problem) is a relatively new challenge that has attracted growing attention from both academia and industry. The imbalanced learning problem is concerned with the performance of learning algorithms in the presence of underrepresented data and severe class distribution skews. Due to the inherent complex characteristics of imbalanced data sets, learning from such data requires new understandings, principles, algorithms, and tools to transform vast amounts of raw data efficiently into information and knowledge representation. In this paper, we provide a comprehensive review of the development of research in learning from imbalanced data. Our focus is to provide a critical review of the nature of the problem, the state-of-the-art technologies, and the current assessment metrics used to evaluate learning performance under the imbalanced learning scenario. Furthermore, in order to stimulate future research in this field, we also highlight the major opportunities and challenges, as well as potential important research directions for learning from imbalanced data.},
  langid = {english},
  file = {C\:\\Users\\USER\\Zotero\\storage\\XWECMLZP\\Haibo He and Garcia - 2009 - Learning from Imbalanced Data.pdf}
}

@article{hassanpourRecognitionMultifontEnglish2014,
  title = {Recognition of {{Multi-font English Numerals}} Using {{SOM Neural Network}}},
  author = {Hassanpour, Hamid and Samadiani, Najmeh},
  date = {2014-07-18},
  journaltitle = {International Journal of Computer Applications},
  shortjournal = {IJCA},
  volume = {98},
  number = {4},
  pages = {37--41},
  issn = {09758887},
  doi = {10.5120/17174-7259},
  url = {http://research.ijcaonline.org/volume98/number4/pxc3897259.pdf},
  urldate = {2022-10-05},
  abstract = {In this paper a new scheme is proposed for off-line recognition of multi-font numeral, using neural networks. Recognition of numerals has been a research area for many years because of its various applications. But there wasn’t much research done for recognition of multi-font numerals. The approaches proposed so far, suffer from larger computation time and training because they must have a set of training samples per each font. They can be extended to recognize many more fonts but the accuracy decreases rapidly. So as to eliminate these drawbacks, in this paper, a method is presented which recognizes 30 different fonts of different sizes varying from size 10 to 28, with an accuracy of 99.55\% on a database of 2000 numeral images. The purpose of this study is to provide a new method to recognize digits based on neural network that can identify the same symbols after training without limitation on the type of the font. In the proposed method, a high accuracy rate is achieved in recognizing digits by extracting the appropriate features without the need for complex neural network architecture. This method uses a self-organizing map (SOM) neural network to measure similarity between the features of digits and the features of the indicators associated with the digits from 0 to 9 obtained in the training stage. In this method, one sample is used for each digit to train the network. So, the proposed method can be used to recognize typed letters without limitation on fonts.},
  langid = {english},
  file = {C\:\\Users\\USER\\Zotero\\storage\\NWGGJICD\\Hassanpour and Samadiani - 2014 - Recognition of Multi-font English Numerals using S.pdf}
}

@incollection{haughianBenchmarkingReplicationCassandra2016,
  title = {Benchmarking {{Replication}} in {{Cassandra}} and {{MongoDB NoSQL Datastores}}},
  booktitle = {Database and {{Expert Systems Applications}}},
  author = {Haughian, Gerard and Osman, Rasha and Knottenbelt, William J.},
  editor = {Hartmann, Sven and Ma, Hui},
  date = {2016},
  volume = {9828},
  pages = {152--166},
  publisher = {{Springer International Publishing}},
  location = {{Cham}},
  doi = {10.1007/978-3-319-44406-2_12},
  url = {http://link.springer.com/10.1007/978-3-319-44406-2_12},
  urldate = {2022-03-16},
  abstract = {The proliferation in Web 2.0 applications has increased the volume, velocity, and variety of data sources which have exceeded the limitations and expected use cases of traditional relational DBMSs. Cloud serving NoSQL data stores address these concerns and provide replication mechanisms to ensure fault tolerance, high availability, and improved scalability. In this paper, we empirically explore the impact of replication on the performance of Cassandra and MongoDB NoSQL datastores. We evaluate the impact of replication in comparison to non-replicated clusters of equal size hosted on a private cloud environment. Our benchmarking experiments are conducted for read and write heavy workloads subject to different access distributions and tunable consistency levels. Our results demonstrate that replication must be taken into consideration in empirical and modelling studies in order to achieve an accurate evaluation of the performance of these datastores.},
  isbn = {978-3-319-44405-5 978-3-319-44406-2},
  langid = {english},
  file = {C\:\\Users\\USER\\Zotero\\storage\\R3LGHZKW\\Haughian et al. - 2016 - Benchmarking Replication in Cassandra and MongoDB .pdf}
}

@inproceedings{hazraOpticalCharacterRecognition2017,
  title = {Optical Character Recognition Using {{KNN}} on Custom Image Dataset},
  booktitle = {2017 8th {{Annual Industrial Automation}} and {{Electromechanical Engineering Conference}} ({{IEMECON}})},
  author = {Hazra, Tapan Kumar and Singh, Dhirendra Pratap and Daga, Nikunj},
  date = {2017-08},
  pages = {110--114},
  publisher = {{IEEE}},
  location = {{Bangkok, Thailand}},
  doi = {10.1109/IEMECON.2017.8079572},
  url = {http://ieeexplore.ieee.org/document/8079572/},
  urldate = {2023-07-09},
  abstract = {The aim is to develop an efficient method which uses a custom image to train the classifier. This OCR extract distinct features from the input image for classifying its contents as characters specifically letters and digits. Input to the system is digital images containing the patterns to be classified. The analysis and recognition of the patterns in images are becoming more complex, yet easy with advances in technological knowledge. Therefore it is proposed to develop sophisticated strategies of pattern analysis to cope with these difficulties. The present work involves application of pattern recognition using KNN to recognize handwritten or printed text.},
  eventtitle = {2017 8th {{Annual Industrial Automation}} and {{Electromechanical Engineering Conference}} ({{IEMECON}})},
  isbn = {978-1-5386-2215-5},
  langid = {english},
  file = {C\:\\Users\\USER\\Zotero\\storage\\ZFMSBGR8\\Hazra et al. - 2017 - Optical character recognition using KNN on custom .pdf}
}

@article{hossainOpticalCharacterRecognition2019,
  title = {Optical {{Character Recognition}} Based on {{Template Matching}}},
  author = {Hossain, Md. Anwar and Afrin, Sadia},
  date = {2019-05-21},
  journaltitle = {Global Journal of Computer Science and Technology},
  shortjournal = {GJCST},
  pages = {31--35},
  issn = {09754172, 09754350},
  doi = {10.34257/GJCSTCVOL19IS2PG31},
  url = {https://globaljournals.org/GJCST_Volume19/4-Optical-Character-Recognition.pdf},
  urldate = {2023-07-14},
  abstract = {This paper presents an innovative design for Optical Character Recognition (OCR) from text images by using the Template Matching method.OCR is an important research area and one of the most successful applications of technology in the field of pattern recognition and artificial intelligence.OCR provides full alphanumeric visualization of printed and handwritten characters by scanning text images and converts it into a corresponding editable text document. The main objective of this system prototype is to develop a prototype for the OCR system and to implement The Template Matching algorithm for provoking the system prototype. In this paper, we took alphabet (A-Z and a-z), and numbers (0-1), grayscale images, bitmap image format were used and recognized the alphabet and numbers by comparing between two images. Besides, we checked accuracy for different fonts of alphabet and numbers. Here we used Matlab R2018a software for the proper implementation of the system.},
  langid = {english},
  file = {C\:\\Users\\USER\\Zotero\\storage\\2J4CHU8P\\Hossain and Afrin - 2019 - Optical Character Recognition based on Template Ma.pdf}
}

@article{huangGANsNLPArchitecture,
  title = {On {{GANs}}, {{NLP}} and {{Architecture}}: {{Combining Human}} and {{Machine Intelligences}} for the {{Generation}} and {{Evaluation}} of {{Meaningful Designs}}},
  author = {Huang, Jeffrey},
  url = {https://www.tandfonline.com/doi/10.1080/24751448.2021.1967060},
  abstract = {Recent advances in Generative Adversarial Networks (GANs) hold considerable promise in architecture, especially in the early, creative stages of design. However, while GANs are capable of producing infinite numbers of new designs based on a given dataset, the architectural relevance and meaningfulness of the results have been questionable. This paper presents an experimental research method to examine how human and artificial intelligences can inform each other to generate new designs that are culturally and architecturally meaningful. The paper contributes to our understanding of GANs in architecture by describing the nuances of different GAN models (SAGAN vs DCGAN) for the generation of new designs, and the use of Natural Language Processing (NLP) for the conceptual analysis of results.}
}

@online{huiGANWaysImprove2018,
  title = {{{GAN}} — {{Ways}} to Improve {{GAN}} Performance},
  author = {Hui, Jonathan},
  date = {2018-06-19},
  url = {https://towardsdatascience.com/gan-ways-to-improve-gan-performance-acf37f9f59b},
  urldate = {2022-05-26},
  abstract = {GAN models can suffer badly in the following areas comparing to other deep networks.     Non-convergence: the models do not converge and worse they become unstable.     Mode collapse: the generator produces limited modes, and     Slow training: the gradient to train the generator vanished.}
}

@incollection{hutchisonEvaluationPoolingOperations2010,
  title = {Evaluation of {{Pooling Operations}} in {{Convolutional Architectures}} for {{Object Recognition}}},
  booktitle = {Artificial {{Neural Networks}} – {{ICANN}} 2010},
  author = {Hutchison, David and Kanade, Takeo and Kittler, Josef and Kleinberg, Jon M. and Mattern, Friedemann and Mitchell, John C. and Naor, Moni and Nierstrasz, Oscar and Pandu Rangan, C. and Steffen, Bernhard and Sudan, Madhu and Terzopoulos, Demetri and Tygar, Doug and Vardi, Moshe Y. and Weikum, Gerhard and Scherer, Dominik and Müller, Andreas and Behnke, Sven},
  editor = {Diamantaras, Konstantinos and Duch, Wlodek and Iliadis, Lazaros S.},
  date = {2010},
  volume = {6354},
  pages = {92--101},
  publisher = {{Springer Berlin Heidelberg}},
  location = {{Berlin, Heidelberg}},
  doi = {10.1007/978-3-642-15825-4_10},
  url = {http://link.springer.com/10.1007/978-3-642-15825-4_10},
  urldate = {2022-06-02},
  abstract = {A common practice to gain invariant features in object recognition models is to aggregate multiple low-level features over a small neighborhood. However, the differences between those models makes a comparison of the properties of different aggregation functions hard. Our aim is to gain insight into different functions by directly comparing them on a fixed architecture for several common object recognition tasks. Empirical results show that a maximum pooling operation significantly outperforms subsampling operations. Despite their shift-invariant properties, overlapping pooling windows are no significant improvement over non-overlapping pooling windows. By applying this knowledge, we achieve state-of-the-art error rates of 4.57\% on the NORB normalized-uniform dataset and 5.6\% on the NORB jittered-cluttered dataset.},
  isbn = {978-3-642-15824-7 978-3-642-15825-4},
  langid = {english},
  file = {C\:\\Users\\USER\\Zotero\\storage\\N2DIAUNV\\Hutchison et al. - 2010 - Evaluation of Pooling Operations in Convolutional .pdf}
}

@article{ImprovementOCRTechnologies2022,
  title = {Improvement in {{OCR Technologies}} in {{Postal Industry Using CNN-RNN Architecture}}: {{Literature Review}}},
  shorttitle = {Improvement in {{OCR Technologies}} in {{Postal Industry Using CNN-RNN Architecture}}},
  date = {2022-09},
  journaltitle = {International Journal of Machine Learning and Computing},
  shortjournal = {IJMLC},
  volume = {12},
  number = {5},
  issn = {20103700},
  doi = {10.18178/ijmlc.2022.12.5.1095},
  url = {http://www.ijmlc.org/index.php?m=content&c=index&a=show&catid=125&id=1291},
  urldate = {2023-06-28},
  abstract = {Convolutional Recurrent Neural Network (CRNN) based architecture is an attractive branch of Optical Character Recognition (OCR) studies. OCR is the process for transforming the image or the text obtained by scanning documents into machine-modifiable or editable format. It belongs to the domain of automatic identification of algorithms, modeled loosely after the animal brains, which are designed for pattern and character recognition. Hence, it falls under the neural networks category. An OCR system relies for the most part on the pre-processing, character/ image segmentation and feature extraction. This technology is an essential segment for automation processed in postal industry to read mail addresses and process mails. The first objective of this paper is to summarize the research that has been conducted in the field and further to present best in practice examples in this regard. Secondly, this research will also discuss about some gaps in the area and try to identify opportunities for future studies.},
  langid = {english},
  file = {C\:\\Users\\USER\\Zotero\\storage\\3IF8QEM2\\2022 - Improvement in OCR Technologies in Postal Industry.pdf}
}

@article{IndexBucketBaywheels,
  title = {Index of Bucket Baywheels Data},
  url = {https://s3.amazonaws.com/baywheels-data/index.html}
}

@online{intelOpenCV,
  type = {Information},
  title = {{{OpenCV}}},
  author = {Intel},
  url = {https://docs.opencv.org/4.x/index.html},
  urldate = {2022-10-15},
  abstract = {OpenCV (Open Source Computer Vision Library: http://opencv.org) is an open-source library that includes several hundreds of computer vision algorithms. The document describes the so-called OpenCV 2.x API, which is essentially a C++ API, as opposed to the C-based OpenCV 1.x API (C API is deprecated and not tested with "C" compiler since OpenCV 2.4 releases)}
}

@inreference{Ireland2022,
  title = {Ireland},
  booktitle = {Wikipedia},
  date = {2022-12-22T18:09:36Z},
  url = {https://en.wikipedia.org/w/index.php?title=Ireland&oldid=1128923242},
  urldate = {2022-12-25},
  abstract = {Ireland ( (listen) YRE-lənd; Irish: Éire [ˈeːɾʲə] (listen); Ulster-Scots: Airlann [ˈɑːrlən]) is an island in the North Atlantic Ocean, in north-western Europe. It is separated from Great Britain to its east by the North Channel, the Irish Sea, and St George's Channel. Ireland is the second-largest island of the British Isles, the third-largest in Europe, and the twentieth-largest on Earth.Geopolitically, Ireland is divided between the Republic of Ireland (officially named Ireland), which covers five-sixths of the island, and Northern Ireland, which is part of the United Kingdom. As of 2022, the population of the entire island is just over 7 million, with 5.1 million living in the Republic of Ireland and 1.9 million in Northern Ireland, ranking it the second-most populous island in Europe after Great Britain.The geography of Ireland comprises relatively low-lying mountains surrounding a central plain, with several navigable rivers extending inland. Its lush vegetation is a product of its mild but changeable climate which is free of extremes in temperature. Much of Ireland was woodland until the end of the Middle Ages. Today, woodland makes up about 10\% of the island, compared with a European average of over 33\%, with most of it being non-native conifer plantations. The Irish climate is influenced by the Atlantic Ocean and thus very moderate, and winters are milder than expected for such a northerly area, although summers are cooler than those in continental Europe. Rainfall and cloud cover are abundant. Gaelic Ireland had emerged by the 1st century AD. The island was Christianised from the 5th century onwards. Following the 12th century Anglo-Norman invasion, England claimed sovereignty. However, English rule did not extend over the whole island until the 16th–17th century Tudor conquest, which led to colonisation by settlers from Britain. In the 1690s, a system of Protestant English rule was designed to materially disadvantage the Catholic majority and Protestant dissenters, and was extended during the 18th century. With the Acts of Union in 1801, Ireland became a part of the United Kingdom. A war of independence in the early 20th century was followed by the partition of the island, thus creating the Irish Free State, which became increasingly sovereign over the following decades, and Northern Ireland, which remained a part of the United Kingdom. Northern Ireland saw much civil unrest from the late 1960s until the 1990s. This subsided following the Good Friday Agreement in 1998. In 1973, the Republic of Ireland joined the European Economic Community while the United Kingdom, and Northern Ireland as part of it, did the same. In 2020, the United Kingdom, Northern Ireland included, left what was by then the European Union (EU). Irish culture has had a significant influence on other cultures, especially in the field of literature. Alongside mainstream Western culture, a strong indigenous culture exists, as expressed through Gaelic games, Irish music, Irish language, and Irish dance. The island's culture shares many features with that of Great Britain, including the English language, and sports such as association football, rugby, horse racing, golf, and boxing.},
  langid = {english},
  annotation = {Page Version ID: 1128923242},
  file = {C\:\\Users\\USER\\Zotero\\storage\\YQVXZIJ3\\Ireland.html}
}

@inproceedings{ishiguroAidedEyesEye2010,
  title = {Aided Eyes: Eye Activity Sensing for Daily Life},
  shorttitle = {Aided Eyes},
  booktitle = {Proceedings of the 1st {{Augmented Human International Conference}}},
  author = {Ishiguro, Yoshio and Mujibiya, Adiyan and Miyaki, Takashi and Rekimoto, Jun},
  date = {2010-04-02},
  pages = {1--7},
  publisher = {{ACM}},
  location = {{Megève France}},
  doi = {10.1145/1785455.1785480},
  url = {https://dl.acm.org/doi/10.1145/1785455.1785480},
  urldate = {2022-09-09},
  abstract = {Our eyes collect a considerable amount of information when we use them to look at objects. In particular, eye movement allows us to gaze at an object and shows our level of interest in the object. In this research, we propose a method that involves real-time measurement of eye movement for human memory enhancement; the method employs gaze-indexed images captured using a video camera that is attached to the user’s glasses. We present a prototype system with an infrared-based corneal limbus tracking method. Although the existing eye tracker systems track eye movement with high accuracy, they are not suitable for daily use because the mobility of these systems is incompatible with a high sampling rate. Our prototype has small phototransistors, infrared LEDs, and a video camera, which make it possible to attach the entire system to the glasses. Additionally, the accuracy of this method is compensated by combining image processing methods and contextual information, such as eye direction, for information extraction. We develop an information extraction system with real-time object recognition in the user’s visual attention area by using the prototype of an eye tracker and a head-mounted camera. We apply this system to (1) fast object recognition by using a SURF descriptor that is limited to the gaze area and (2) descriptor matching of a past-images database. Face recognition by using haar-like object features and text logging by using OCR technology is also implemented. The combination of a low-resolution camera and a high-resolution, wide-angle camera is studied for high daily usability. The possibility of gaze-guided computer vision is discussed in this paper, as is the topic of communication by the photo transistor in the eye tracker and the development of a sensor system that has a high transparency.},
  eventtitle = {{{AH}} '10: 2010 {{Augmented Human International Conference}}},
  isbn = {978-1-60558-825-4},
  langid = {english},
  file = {C\:\\Users\\USER\\Zotero\\storage\\5Q2Z5X3H\\Ishiguro et al. - 2010 - Aided eyes eye activity sensing for daily life.pdf}
}

@article{ivanescuImportancePredictionModel2022,
  title = {The Importance of Prediction Model Validation and Assessment in Obesity and Nutrition Research},
  author = {Ivanescu, A E},
  date = {2022-10-09},
  journaltitle = {International Journal of Obesity},
  url = {https://www.nature.com/articles/ijo2015214},
  abstract = {Deriving statistical models to predict one variable from one or more other variables, or predictive modeling, is an important activity in obesity and nutrition research. To determine the quality of the model, it is necessary to quantify and report the predictive validity of the derived models. Conducting validation of the predictive measures provides essential information to the research community about the model. Unfortunately, many articles fail to account for the nearly inevitable reduction in predictive ability that occurs when a model derived on one data set is applied to a new data set. Under some circumstances, the predictive validity can be reduced to nearly zero. In this overview, we explain why reductions in predictive validity occur, define the metrics commonly used to estimate the predictive validity of a model (for example, coefficient of determination (R2), mean squared error, sensitivity, specificity, receiver operating characteristic and concordance index) and describe methods to estimate the predictive validity (for example, cross-validation, bootstrap, and adjusted and shrunken R2). We emphasize that methods for estimating the expected reduction in predictive ability of a model in new samples are available and this expected reduction should always be reported when new predictive models are introduced.}
}

@article{janvierSubchondralTibialBone2017,
  title = {Subchondral Tibial Bone Texture Analysis Predicts Knee Osteoarthritis Progression: Data from the {{Osteoarthritis Initiative}}},
  shorttitle = {Subchondral Tibial Bone Texture Analysis Predicts Knee Osteoarthritis Progression},
  author = {Janvier, T. and Jennane, R. and Valery, A. and Harrar, K. and Delplanque, M. and Lelong, C. and Loeuille, D. and Toumi, H. and Lespessailles, E.},
  date = {2017-02},
  journaltitle = {Osteoarthritis and Cartilage},
  shortjournal = {Osteoarthritis and Cartilage},
  volume = {25},
  number = {2},
  pages = {259--266},
  issn = {10634584},
  doi = {10.1016/j.joca.2016.10.005},
  url = {https://linkinghub.elsevier.com/retrieve/pii/S1063458416303144},
  urldate = {2022-04-02},
  abstract = {Objectives: To examine whether trabecular bone texture (TBT) parameters assessed on computed radiographs could predict knee osteoarthritis (OA) progression. Methods: This study was performed using data from the Osteoarthritis Initiative (OAI). 1647 knees in 1124 patients had bilateral fixed flexion radiographs acquired 48 months apart. Images were semiautomatically segmented to extract a patchwork of regions of interest (ROI). A fractal texture analysis was performed using different methods. OA progression was defined as an increase in the joint space narrowing (JSN) over 48 months. The predictive ability of TBT was evaluated using logistic regression and receiver operating characteristic (ROC) curve. An optimization method for features selection was used to reduce the size of models and assess the impact of each ROI. Results: Fractal dimensions (FD's) were predictive of the JSN progression for each method tested with an area under the ROC curve (AUC) up to 0.71. Baseline JSN grade was not correlated with TBT parameters (R {$<$} 0.21) but had the same predictive capacity (AUC 0.71). The most predictive model included the clinical covariates (age, gender, body mass index (BMI)), JSN and TBT parameters (AUC 0.77). From a statistical point of view we found higher differences in TBT parameters computed in medial ROI between progressors and non-progressors. However, the integration of TBT results from the whole patchwork including the lateral ROIs in the model provided the best predictive model. Conclusions: Our findings indicate that TBT parameters assessed in different locations in the joint provided a good predictive ability to detect knee OA progression. © 2016 Osteoarthritis Research Society International. Published by Elsevier Ltd. All rights reserved.},
  langid = {english},
  file = {C\:\\Users\\USER\\Zotero\\storage\\MW4R9IZB\\Janvier et al. - 2017 - Subchondral tibial bone texture analysis predicts .pdf}
}

@video{jelvixCassandraVsMongo2020,
  entrysubtype = {film},
  title = {Cassandra {{Vs Mongo}}},
  editor = {Jelvix},
  editortype = {director},
  date = {2020-09-01},
  url = {https://www.youtube.com/watch?v=3z2EzILA3Rk},
  abstract = {In this video, we’ll give you a clear understanding of what Cassandra and MongoDB are and what they are not.}
}

@article{jimenez-valverdeInsightsAreaReceiver2012,
  title = {Insights into the Area under the Receiver Operating Characteristic Curve ({{AUC}}) as a Discrimination Measure in Species Distribution Modelling: {{Insights}} into the {{AUC}}},
  shorttitle = {Insights into the Area under the Receiver Operating Characteristic Curve ({{AUC}}) as a Discrimination Measure in Species Distribution Modelling},
  author = {Jiménez-Valverde, Alberto},
  date = {2012-04},
  journaltitle = {Global Ecology and Biogeography},
  volume = {21},
  number = {4},
  pages = {498--507},
  issn = {1466822X},
  doi = {10.1111/j.1466-8238.2011.00683.x},
  url = {https://onlinelibrary.wiley.com/doi/10.1111/j.1466-8238.2011.00683.x},
  urldate = {2022-02-12},
  abstract = {Aim The area under the receiver operating characteristic (ROC) curve (AUC) is a widely used statistic for assessing the discriminatory capacity of species distribution models. Here, I used simulated data to examine the interdependence of the AUC and classical discrimination measures (sensitivity and specificity) derived for the application of a threshold. I shall further exemplify with simulated data the implications of using the AUC to evaluate potential versus realized distribution models.},
  langid = {english},
  file = {C\:\\Users\\USER\\Zotero\\storage\\SKX23TMB\\Jiménez-Valverde - 2012 - Insights into the area under the receiver operatin.pdf}
}

@article{jonesEvenIfYou2012,
  title = {“{{Even}} If {{You Know Everything You Can Forget}}”: {{Health Worker Perceptions}} of {{Mobile Phone Text-Messaging}} to {{Improve Malaria Case-Management}} in {{Kenya}}},
  shorttitle = {“{{Even}} If {{You Know Everything You Can Forget}}”},
  author = {Jones, Caroline O. H. and Wasunna, Beatrice and Sudoi, Raymond and Githinji, Sophie and Snow, Robert W. and Zurovac, Dejan},
  editor = {Shiff, Clive},
  date = {2012-06-13},
  journaltitle = {PLoS ONE},
  shortjournal = {PLoS ONE},
  volume = {7},
  number = {6},
  pages = {e38636},
  issn = {1932-6203},
  doi = {10.1371/journal.pone.0038636},
  url = {https://dx.plos.org/10.1371/journal.pone.0038636},
  urldate = {2022-03-19},
  abstract = {This paper presents the results of a qualitative study to investigate the perceptions and experiences of health workers involved in a a cluster-randomized controlled trial of a novel intervention to improve health worker malaria casemanagement in 107 government health facilities in Kenya. The intervention involved sending text-messages about paediatric outpatient malaria case-management accompanied by ‘‘motivating’’ quotes to health workers’ mobile phones. Ten malaria messages were developed reflecting recommendations from the Kenyan national guidelines. Two messages were delivered per day for 5 working days and the process was repeated for 26 weeks (May to October 2009). The accompanying quotes were unique to each message. The intervention was delivered to 119 health workers and there were significant improvements in correct artemether-lumefantrine (AL) management both immediately after the intervention (November 2009) and 6 months later (May 2010). In-depth interviews with 24 health workers were undertaken to investigate the possible drivers of this change. The results suggest high acceptance of all components of the intervention, with the active delivery of information in an on the job setting, the ready availability of new and stored text messages and the perception of being kept ‘up to date’ as important factors influencing practice. Applying the construct of stages of change we infer that in this intervention the SMS messages were operating primarily at the action and maintenance stages of behaviour change achieving their effect by creating an enabling environment and providing a prompt to action for the implementation of case management practices that had already been accepted as the clinical norm by the health workers. Future trials testing the effectiveness of SMS reminders in creating an enabling environment for the establishment of new norms in clinical practice as well as in providing a prompt to action for the implementation of the new case-management guidelines are justified.},
  langid = {english},
  file = {C\:\\Users\\USER\\Zotero\\storage\\XML9KJD9\\Jones et al. - 2012 - “Even if You Know Everything You Can Forget” Heal.pdf}
}

@unpublished{jonesOpticalCharacterRecognition,
  title = {Optical {{Character Recognition}} in {{Python}}},
  author = {Jones, Granatyr},
  url = {https://www.udemy.com/course/ocr-optical-character-recognition-in-python/learn/lecture/31791068#overview},
  urldate = {2022-10-15},
  abstract = {Within the area of Computer Vision is the sub-area of Optical Character Recognition (OCR), which aims to transform images into texts. OCR can be described as converting images containing typed, handwritten or printed text into characters that a machine can understand. It is possible to convert scanned or photographed documents into texts that can be edited in any tool, such as the Microsoft Word. A common application is automatic form reading, in which you can send a photo of your credit card or your driver's license, and the system can read all your data without the need to type them manually. A self-driving car can use OCR to read traffic signs and a parking lot can guarantee access by reading the license plate of the cars!}
}

@article{jordanHyperparameterTuningMachine2017,
  title = {Hyperparameter Tuning for Machine Learning Models.},
  author = {Jordan, Jeremy},
  date = {2017-11-02},
  journaltitle = {jeremyjordan.me},
  url = {https://www.jeremyjordan.me/hyperparameter-tuning/},
  abstract = {When creating a machine learning model, you'll be presented with design choices as to how to define your model architecture. Often times, we don't immediately know what the optimal model architecture should be for a given model, and thus we'd like to be able to explore a range of possibilities. In true machine learning fashion, we'll ideally ask the machine to perform this exploration and select the optimal model architecture automatically. Parameters which define the model architecture are referred to as hyperparameters and thus this process of searching for the ideal model architecture is referred to as hyperparameter tuning.}
}

@inproceedings{joshuaDevelopmentImageProcessing2023,
  title = {Development of an {{Image Processing Techniques}} for {{Vehicle Classification Using OCR}} and {{SVM}}},
  booktitle = {2023 {{International Conference}} on {{Science}}, {{Engineering}} and {{Business}} for {{Sustainable Development Goals}} ({{SEB-SDG}})},
  author = {Joshua, Ishola Oluwaseun and Arowolo, Michael Olaolu and Adebiyi, Marion O. and Oluwaseun, Ogundokun Roseline and Gbolagade, Kazeem Alagbe},
  date = {2023-04-05},
  pages = {1--9},
  publisher = {{IEEE}},
  location = {{Omu-Aran, Nigeria}},
  doi = {10.1109/SEB-SDG57117.2023.10124622},
  url = {https://ieeexplore.ieee.org/document/10124622/},
  urldate = {2023-07-09},
  abstract = {Image processing is a method for enhancing unprocessed images from cameras on aircraft, spacecraft, and satellites as well as images taken regularly for a variety of uses. In general, the following strategies can be used to categorize all image processing operations: Images are represented in several ways, which are referred to as image representation, image preprocessing, image enhancement, image restoration, image analysis, picture reconstruction, and image data compression. The first radiometric normalization, geometric distortion correction, and noise removal of the raw image data been discussed in the past. The goal of the information extraction procedures is to automate the identification of tone in a scene by replacing the visual examination of image data with quantitative techniques. This entails analyzing multispectral image data and establishing the earth cover identification of each pixel in an image using statistically based decision procedures. The goal of the classification procedure is to sort all of the pixels in a digital image into one of several different earth cover classes or themes. The purpose of this study is to examine various image processing approaches and algorithms, many sorts of image processing algorithms: Optical Character Recognition (OCR) and Supporting Vector Machine (SVM) a feature extraction technique, on the vehicle classification dataset and had accurate results of 90\% for SVM and 95\% for OCR, to further improve the performance of machine algorithms in terms of accuracy for image processing technique using a vehicle. This study can be used for vehicle classification research, it also advances and improves the performance of the system in terms of accurate detection.},
  eventtitle = {2023 {{International Conference}} on {{Science}}, {{Engineering}} and {{Business}} for {{Sustainable Development Goals}} ({{SEB-SDG}})},
  isbn = {9798350324785},
  langid = {english},
  file = {C\:\\Users\\USER\\Zotero\\storage\\22ZMQRTX\\Joshua et al. - 2023 - Development of an Image Processing Techniques for .pdf}
}

@article{kamiranDataPreprocessingTechniques2012,
  title = {Data Preprocessing Techniques for Classification without Discrimination},
  author = {Kamiran, Faisal and Calders, Toon},
  date = {2012-10},
  journaltitle = {Knowledge and Information Systems},
  shortjournal = {Knowl Inf Syst},
  volume = {33},
  number = {1},
  pages = {1--33},
  issn = {0219-1377, 0219-3116},
  doi = {10.1007/s10115-011-0463-8},
  url = {http://link.springer.com/10.1007/s10115-011-0463-8},
  urldate = {2022-02-12},
  abstract = {Recently, the following Discrimination-Aware Classification Problem was introduced: Suppose we are given training data that exhibit unlawful discrimination; e.g., toward sensitive attributes such as gender or ethnicity. The task is to learn a classifier that optimizes accuracy, but does not have this discrimination in its predictions on test data. This problem is relevant in many settings, such as when the data are generated by a biased decision process or when the sensitive attribute serves as a proxy for unobserved features. In this paper, we concentrate on the case with only one binary sensitive attribute and a two-class classification problem. We first study the theoretically optimal trade-off between accuracy and non-discrimination for pure classifiers. Then, we look at algorithmic solutions that preprocess the data to remove discrimination before a classifier is learned. We survey and extend our existing data preprocessing techniques, being suppression of the sensitive attribute, massaging the dataset by changing class labels, and reweighing or resampling the data to remove discrimination without relabeling instances. These preprocessing techniques have been implemented in a modified version of Weka and we present the results of experiments on real-life data.},
  langid = {english},
  file = {C\:\\Users\\USER\\Zotero\\storage\\A4GFXUSG\\Kamiran and Calders - 2012 - Data preprocessing techniques for classification w.pdf}
}

@article{kangPreventionHandlingMissing2013,
  title = {The Prevention and Handling of the Missing Data},
  author = {Kang, Hyun},
  date = {2013},
  journaltitle = {Korean Journal of Anesthesiology},
  shortjournal = {Korean J Anesthesiol},
  volume = {64},
  number = {5},
  pages = {402},
  issn = {2005-6419, 2005-7563},
  doi = {10.4097/kjae.2013.64.5.402},
  url = {http://ekja.org/journal/view.php?doi=10.4097/kjae.2013.64.5.402},
  urldate = {2022-02-13},
  langid = {english},
  file = {C\:\\Users\\USER\\Zotero\\storage\\M9ZR26JM\\Kang - 2013 - The prevention and handling of the missing data.pdf}
}

@article{karrasStyleBasedGeneratorArchitecture,
  title = {A {{Style-Based Generator Architecture}} for {{Generative Adversarial Networks}}},
  author = {Karras, Tero and Laine, Samuli and Aila, Timo},
  pages = {12},
  abstract = {We propose an alternative generator architecture for generative adversarial networks, borrowing from style transfer literature. The new architecture leads to an automatically learned, unsupervised separation of high-level attributes (e.g., pose and identity when trained on human faces) and stochastic variation in the generated images (e.g., freckles, hair), and it enables intuitive, scale-specific control of the synthesis. The new generator improves the state-of-the-art in terms of traditional distribution quality metrics, leads to demonstrably better interpolation properties, and also better disentangles the latent factors of variation. To quantify interpolation quality and disentanglement, we propose two new, automated methods that are applicable to any generator architecture. Finally, we introduce a new, highly varied and high-quality dataset of human faces.},
  langid = {english},
  file = {C\:\\Users\\USER\\Zotero\\storage\\ELEJKIMV\\Karras et al. - A Style-Based Generator Architecture for Generativ.pdf}
}

@article{kimLearningDiscoverCrossDomain,
  title = {Learning to {{Discover Cross-Domain Relations}}  with {{Generative Adversarial Networks}}},
  author = {Kim, Taeksoo and Cha, Moonsu and Kim, Hyunsoo and Lee, Jung Kwon and Kim, Jiwon},
  pages = {10},
  abstract = {While humans easily recognize relations between data from different domains without any supervision, learning to automatically discover them is in general very challenging and needs many ground-truth pairs that illustrate the relations. To avoid costly pairing, we address the task of discovering cross-domain relations given unpaired data. We propose a method based on generative adversarial networks that learns to discover relations between different domains (DiscoGAN). Using the discovered relations, our proposed network successfully transfers style from one domain to another while preserving key attributes such as orientation and face identity.},
  langid = {english},
  file = {C\:\\Users\\USER\\Zotero\\storage\\HXBN9RRE\\Kim et al. - Learning to Discover Cross-Domain Relations  with .pdf}
}

@article{kshetryImagePreprocessingModified2022,
  title = {Image {{Preprocessing}} and {{Modified Adaptive Thresholding}} for {{Improving Ocr}}},
  author = {Kshetry, Rohan Lal},
  date = {2022},
  journaltitle = {SSRN Electronic Journal},
  shortjournal = {SSRN Journal},
  issn = {1556-5068},
  doi = {10.2139/ssrn.4135966},
  url = {https://www.ssrn.com/abstract=4135966},
  urldate = {2023-06-26},
  abstract = {In this paper I have proposed a method to find the major pixel intensity inside the text and thresholding an image accordingly to make it easier to be used for optical character recognition (OCR) models. In our method, instead of editing whole image, I are removing all other features except the text boundaries and the color filling them. In this approach, the grayscale intensity of the letters from the input image are used as one of thresholding parameters. The performance of the developed model is finally validated with input images, with and without image processing followed by OCR by PyTesseract. Based on the results obtained, it can be observed that this algorithm can be efficiently applied in the field of image processing for OCR.},
  langid = {english},
  file = {C\:\\Users\\USER\\Zotero\\storage\\J85SSUQ4\\Kshetry - 2022 - Image Preprocessing and Modified Adaptive Threshol.pdf}
}

@inproceedings{kulkarniOpticalNumeralRecognition2016,
  title = {Optical Numeral Recognition Algorithm for Seven Segment Display},
  booktitle = {2016 {{Conference}} on {{Advances}} in {{Signal Processing}} ({{CASP}})},
  author = {Kulkarni, Prachi H. and Kute, Pratik D.},
  date = {2016-06},
  pages = {397--401},
  publisher = {{IEEE}},
  location = {{Pune, India}},
  doi = {10.1109/CASP.2016.7746203},
  url = {http://ieeexplore.ieee.org/document/7746203/},
  urldate = {2022-10-05},
  abstract = {The paper discusses an algorithm for the recognition of seven segment numbers on a display, so that the algorithm can be utilized for applications such as automated reading of LCD-based meters. The algorithm outlines a 7-step process consisting of four types of operations- Object Detection, Noise Removal, Image Segmentation and Numeral Recognition based on pixel density feature extraction. The performance of the algorithm is evaluated, by simulation and field tests, for robustness to variations of digit positions, brightness, contrast, tilt and noise. The recognition rate of the algorithm is 79\% when tested over a wide range of variation in illumination and angular tilt conditions.},
  eventtitle = {2016 {{Conference}} on {{Advances}} in {{Signal Processing}} ({{CASP}})},
  isbn = {978-1-5090-0849-0},
  langid = {english},
  file = {C\:\\Users\\USER\\Zotero\\storage\\LIMRYR5P\\Kulkarni and Kute - 2016 - Optical numeral recognition algorithm for seven se.pdf}
}

@article{lecunConvolutionalNetworksImages,
  title = {Convolutional {{Networks}} for {{Images}}, {{Speech}}, and {{Time-Series}}},
  author = {LeCun, Yann and Bengio, Yoshua and Laboratories, T Bell},
  pages = {14},
  langid = {english},
  file = {C\:\\Users\\USER\\Zotero\\storage\\86W73INV\\LeCun et al. - Convolutional Networks for Images, Speech, and Tim.pdf}
}

@article{leichtensternAnalysisBuiltinMobile,
  title = {Analysis of {{Built-in Mobile Phone Sensors}} for {{Supporting Interactions}} with the {{Real World}}},
  author = {Leichtenstern, Karin and Luca, Alexander De and Rukzio, Enrico},
  pages = {4},
  abstract = {There is currently a lot of research going on in the field of mobile interaction with the real world. So far, the environment where the mobile phone is used is mainly perceived as an unpleasant and disturbing factor. Therefore it has rarely been used as a part of the interaction. But on the other hand there is a huge potential for new kinds of the interactions and novel services. Until now, mostly sophisticated and novel hardware has been used for the development of prototypes. In this paper we investigate which sensors are already built-in in modern mobile phones and analyze how they can be employed in real world interactions. Our focus is on investigating how mobile phone sensors can be accessed using the J2ME platform. We analyze the performance and quality of the recorded media data, and where it can be processed. Finally, we conclude with a discussion on what can already be accomplished with today’s mobile phones and which new functions are potentially desired.},
  langid = {english},
  file = {C\:\\Users\\USER\\Zotero\\storage\\4JLHUDR2\\Leichtenstern et al. - Analysis of Built-in Mobile Phone Sensors for Supp.pdf}
}

@inproceedings{liAttentionBasedRNN2017,
  title = {Attention {{Based RNN Model}} for {{Document Image Quality Assessment}}},
  booktitle = {2017 14th {{IAPR International Conference}} on {{Document Analysis}} and {{Recognition}} ({{ICDAR}})},
  author = {Li, Pengchao and Peng, Liangrui and Cai, Junyang and Ding, Xiaoqing and Ge, Shuangkui},
  date = {2017-11},
  pages = {819--825},
  publisher = {{IEEE}},
  location = {{Kyoto}},
  doi = {10.1109/ICDAR.2017.139},
  url = {http://ieeexplore.ieee.org/document/8270070/},
  urldate = {2023-07-14},
  abstract = {Document Image Quality Assessment (DIQA) is an essential step preceding Optical Character Recognition (OCR). In this paper we propose an attention based Recurrent Neural Network (RNN) model for camera based DIQA. Convolutional Neural Network (CNN) and RNN are integrated into our model to capture spatial features for several glimpse regions step by step within an image patch. Reinforcement learning is adopted to train a locator to generate the optimal location of a glimpse region for the next time step so that attention can be payed to the salient part. Given an input document image, patches are generated with a sliding window, and the pure background ones are sifted out. Quality scores are obtained for all the sifted patches by applying the proposed attention based RNN method, and the patch scores are averaged over each input image as the result of DIQA. We conduct experiments on two public datasets and make comparisons with several other reported methods. Experimental results show that our model achieves the state of the art performance.},
  eventtitle = {2017 14th {{IAPR International Conference}} on {{Document Analysis}} and {{Recognition}} ({{ICDAR}})},
  isbn = {978-1-5386-3586-5},
  langid = {english},
  file = {C\:\\Users\\USER\\Zotero\\storage\\TKPDM6I9\\Li et al. - 2017 - Attention Based RNN Model for Document Image Quali.pdf}
}

@online{linMicrosoftCOCOCommon2015,
  title = {Microsoft {{COCO}}: {{Common Objects}} in {{Context}}},
  shorttitle = {Microsoft {{COCO}}},
  author = {Lin, Tsung-Yi and Maire, Michael and Belongie, Serge and Bourdev, Lubomir and Girshick, Ross and Hays, James and Perona, Pietro and Ramanan, Deva and Zitnick, C. Lawrence and Dollár, Piotr},
  date = {2015-02-20},
  eprint = {1405.0312},
  eprinttype = {arxiv},
  eprintclass = {cs},
  url = {http://arxiv.org/abs/1405.0312},
  urldate = {2022-10-05},
  abstract = {We present a new dataset with the goal of advancing the state-of-the-art in object recognition by placing the question of object recognition in the context of the broader question of scene understanding. This is achieved by gathering images of complex everyday scenes containing common objects in their natural context. Objects are labeled using per-instance segmentations to aid in precise object localization. Our dataset contains photos of 91 objects types that would be easily recognizable by a 4 year old. With a total of 2.5 million labeled instances in 328k images, the creation of our dataset drew upon extensive crowd worker involvement via novel user interfaces for category detection, instance spotting and instance segmentation. We present a detailed statistical analysis of the dataset in comparison to PASCAL, ImageNet, and SUN. Finally, we provide baseline performance analysis for bounding box and segmentation detection results using a Deformable Parts Model.},
  langid = {english},
  pubstate = {preprint},
  keywords = {Computer Science - Computer Vision and Pattern Recognition},
  file = {C\:\\Users\\USER\\Zotero\\storage\\NG7MH7V4\\Lin et al. - 2015 - Microsoft COCO Common Objects in Context.pdf}
}

@article{liTrOCRTransformerBasedOptical2023,
  title = {{{TrOCR}}: {{Transformer-Based Optical Character Recognition}} with {{Pre-trained Models}}},
  shorttitle = {{{TrOCR}}},
  author = {Li, Minghao and Lv, Tengchao and Chen, Jingye and Cui, Lei and Lu, Yijuan and Florencio, Dinei and Zhang, Cha and Li, Zhoujun and Wei, Furu},
  date = {2023-06-26},
  journaltitle = {Proceedings of the AAAI Conference on Artificial Intelligence},
  shortjournal = {AAAI},
  volume = {37},
  number = {11},
  pages = {13094--13102},
  issn = {2374-3468, 2159-5399},
  doi = {10.1609/aaai.v37i11.26538},
  url = {https://ojs.aaai.org/index.php/AAAI/article/view/26538},
  urldate = {2023-07-14},
  abstract = {Text recognition is a long-standing research problem for document digitalization. Existing approaches are usually built based on CNN for image understanding and RNN for charlevel text generation. In addition, another language model is usually needed to improve the overall accuracy as a postprocessing step. In this paper, we propose an end-to-end text recognition approach with pre-trained image Transformer and text Transformer models, namely TrOCR, which leverages the Transformer architecture for both image understanding and wordpiece-level text generation. The TrOCR model is simple but effective, and can be pre-trained with large-scale synthetic data and fine-tuned with human-labeled datasets. Experiments show that the TrOCR model outperforms the current state-of-the-art models on the printed, handwritten and scene text recognition tasks. The TrOCR models and code are publicly available at https://aka.ms/trocr.},
  langid = {english},
  file = {C\:\\Users\\USER\\Zotero\\storage\\AVUQ32U3\\Li et al. - 2023 - TrOCR Transformer-Based Optical Character Recogni.pdf}
}

@online{mahtoSceneTextDetection2021,
  title = {Scene {{Text Detection And Recognition Using EAST And Tesseract}}},
  author = {Mahto, Paritosh},
  date = {2021-06-06},
  url = {https://towardsdatascience.com/scene-text-detection-and-recognition-using-east-and-tesseract-6f07c249f5de},
  abstract = {In this era of digitization, the need for the extraction of textual information from different sources has risen to a large extent. Fortunately, recent advances in Computer Vision allow us to make great strides in easing the burden of text detection and other document analysis and understanding. In Computer Vision the method of converting the text present in images or scanned documents to a machine-readable format that can later be edited, searched, and can be used for further processing is known as Optical Character Recognition (OCR).},
  organization = {{Towards Data Science}}
}

@incollection{mancasNaturalSceneText2007,
  title = {Natural {{Scene Text Understanding}}},
  booktitle = {Vision {{Systems}}: {{Segmentation}} and {{Pattern Recognition}}},
  author = {Mancas, Celine and Gosseli, Bernard},
  editor = {Obinata, Goro and Dutt, Ashish},
  date = {2007-06-01},
  publisher = {{I-Tech Education and Publishing}},
  doi = {10.5772/4966},
  url = {http://www.intechopen.com/books/vision_systems_segmentation_and_pattern_recognition/natural_scene_text_understanding},
  urldate = {2022-11-06},
  isbn = {978-3-902613-05-9},
  langid = {english},
  file = {C\:\\Users\\USER\\Zotero\\storage\\NDT9N9L8\\Mancas and Gosseli - 2007 - Natural Scene Text Understanding.pdf}
}

@article{maoLeastSquaresGenerative,
  title = {Least {{Squares Generative Adversarial Networks}}},
  author = {Mao, Xudong and Li, Qing and Xie, Haoran and Lau, Raymond Y K and Wang, Zhen and Smolley, Stephen Paul},
  pages = {16},
  abstract = {Unsupervised learning with generative adversarial networks (GANs) has proven hugely successful. Regular GANs hypothesize the discriminator as a classifier with the sigmoid cross entropy loss function. However, we found that this loss function may lead to the vanishing gradients problem during the learning process. To overcome such a problem, we propose in this paper the Least Squares Generative Adversarial Networks (LSGANs) which adopt the least squares loss function for the discriminator. We show that minimizing the objective function of LSGAN yields minimizing the Pearson χ2 divergence. There are two benefits of LSGANs over regular GANs. First, LSGANs are able to generate higher quality images than regular GANs. Second, LSGANs perform more stable during the learning process. We evaluate LSGANs on five scene datasets and the experimental results show that the images generated by LSGANs are of better quality than the ones generated by regular GANs. We also conduct two comparison experiments between LSGANs and regular GANs to illustrate the stability of LSGANs.},
  langid = {english},
  file = {C\:\\Users\\USER\\Zotero\\storage\\YNYAN4DJ\\Mao et al. - Least Squares Generative Adversarial Networks.pdf}
}

@online{martinezUsingGeneralAdversarial2018,
  title = {Using {{General Adversarial Networks}} for {{Marketing}}: {{A Case Study}} of {{Airbnb}}},
  shorttitle = {Using {{General Adversarial Networks}} for {{Marketing}}},
  author = {Martinez, Richard Diehl and Kamalu, John Kaleialoha},
  date = {2018-06-29},
  eprint = {1806.11432},
  eprinttype = {arxiv},
  eprintclass = {cs},
  url = {http://arxiv.org/abs/1806.11432},
  urldate = {2022-05-29},
  abstract = {In this paper, we examine the use case of general adversarial networks (GANs) in the field of marketing. In particular, we analyze how GAN models can replicate text patterns from successful product listings on Airbnb, a peer-to-peer online market for short-term apartment rentals. To do so, we define the Diehl-MartinezKamalu (DMK) loss function as a new class of functions that forces the models generated output to include a set of user-defined keywords. This allows the general adversarial network to recommend a way of rewording the phrasing of a listing description to increase the likelihood that it is booked. Although we tailor our analysis to Airbnb data, we believe this framework establishes a more general model for how generative algorithms can be used to produce text samples for the purposes of marketing.},
  langid = {english},
  pubstate = {preprint},
  keywords = {Computer Science - Computation and Language},
  file = {C\:\\Users\\USER\\Zotero\\storage\\CPFB32RK\\Martinez and Kamalu - 2018 - Using General Adversarial Networks for Marketing .pdf}
}

@online{MobilePhoneSensing2012,
  title = {Mobile {{Phone Sensing}}},
  date = {2012-05-21},
  url = {https://www.cl.cam.ac.uk/teaching/1112/MobSensSys/mobile-lecture8.pdf}
}

@report{mohyuddinCassandraQueryCheat2022,
  title = {Cassandra {{Query Cheat Sheet}}},
  author = {Mohyuddin, Usman},
  date = {2022-01-28},
  url = {https://www.baeldung.com/cassandra-query-cheat-sheet},
  abstract = {Sometimes, we need a quick reference guide to get started in our learning path. In particular, a cheat sheet is a document that contains all the critical information. In this tutorial, we'll learn the essential concepts of Cassandra query language (CQL) and how to apply them using a cheat sheet that we'll build along the way.}
}

@article{nikoraRenewalResistanceMoko2007,
  title = {Renewal and Resistance: Moko in Contemporary {{New Zealand}}},
  shorttitle = {Renewal and Resistance},
  author = {Nikora, Linda Waimarie and Rua, Mohi and Te Awekotuku, Ngahuia},
  date = {2007-11},
  journaltitle = {Journal of Community \& Applied Social Psychology},
  shortjournal = {J. Community. Appl. Soc. Psychol.},
  volume = {17},
  number = {6},
  pages = {477--489},
  issn = {10529284, 10991298},
  doi = {10.1002/casp.942},
  url = {https://onlinelibrary.wiley.com/doi/10.1002/casp.942},
  urldate = {2022-06-02},
  abstract = {Moko is still here, contrary to the widely held belief that the art and custom of moko—Maori skin adornment—had vanished from New Zealand communities. Over the last two decades an increasingly visible number of Maori have revived and renewed the practice, taking colour into their skin. As an indigenous people, re-taking moko confronts and refutes the myth of a ‘dying race’. It calls on Maori to recommit to strong Maori identities, customs and traditions and challenges the viewer to re-examine their social representations of moko and moko wearers. This paper reports the resistance strategies of a group of 83 moko wearers. Strategies include (1) educating, representing and reconstructing; (2) invalidating and minimizing representations; (3) building and enhancing social networks; and (4) securing cultural identity and pride. They reflect the celebration of cultural resilience. Copyright \# 2007 John Wiley \& Sons, Ltd.},
  langid = {english},
  file = {C\:\\Users\\USER\\Zotero\\storage\\87ZL6Z96\\Nikora et al. - 2007 - Renewal and resistance moko in contemporary New Z.pdf}
}

@book{oneilWeaponsMathDestruction2016,
  title = {Weapons of Math Destruction: How Big Data Increases Inequality and Threatens Democracy},
  shorttitle = {Weapons of Math Destruction},
  author = {O'Neil, Cathy},
  date = {2016},
  edition = {First edition},
  publisher = {{Crown}},
  location = {{New York}},
  isbn = {978-0-553-41881-1 978-0-553-41883-5},
  langid = {english},
  pagetotal = {259},
  keywords = {21st century,Big data,Democracy,Mathematical models Moral and ethical aspects,Political aspects,Social aspects,Social conditions,Social indicators,United States},
  file = {C\:\\Users\\USER\\Zotero\\storage\\EIF7YT6V\\O'Neil - 2016 - Weapons of math destruction how big data increase.pdf}
}

@article{osheaIntroductionConvolutionalNeural,
  title = {An {{Introduction}} to {{Convolutional Neural Networks}}},
  author = {O’Shea, Keiron and Nash, Ryan},
  pages = {11},
  abstract = {The field of machine learning has taken a dramatic twist in recent times, with the rise of the Artificial Neural Network (ANN). These biologically inspired computational models are able to far exceed the performance of previous forms of artificial intelligence in common machine learning tasks. One of the most impressive forms of ANN architecture is that of the Convolutional Neural Network (CNN). CNNs are primarily used to solve difficult image-driven pattern recognition tasks and with their precise yet simple architecture, offers a simplified method of getting started with ANNs.},
  langid = {english},
  file = {C\:\\Users\\USER\\Zotero\\storage\\TWEU5UW3\\O’Shea and Nash - An Introduction to Convolutional Neural Networks.pdf}
}

@online{ottCassandraUnableQuery2019,
  title = {Cassandra Unable to Query Sum of Rows from a Table},
  author = {Ott, Alex},
  date = {2019-05-28},
  url = {https://stackoverflow.com/questions/56335936/cassandra-unable-to-query-sum-of-rows-from-a-table},
  abstract = {I am using Cassandra database for capturing and saving a simple network sniffer data, but because the number of rows in the table is greater than 20M+ rows, it is unable to run any aggregate function such as sum or count.}
}

@inproceedings{pelegrisNovelMethodDetect2010,
  title = {A Novel Method to Detect {{Heart Beat Rate}} Using a Mobile Phone},
  booktitle = {2010 {{Annual International Conference}} of the {{IEEE Engineering}} in {{Medicine}} and {{Biology}}},
  author = {Pelegris, P and Banitsas, K and Orbach, T and Marias, K},
  date = {2010-08},
  pages = {5488--5491},
  publisher = {{IEEE}},
  location = {{Buenos Aires}},
  doi = {10.1109/IEMBS.2010.5626580},
  url = {http://ieeexplore.ieee.org/document/5626580/},
  urldate = {2022-03-19},
  abstract = {Heart Beat Rate calculation has traditionally been conducted using specialized hardware most commonly in the form of pulse oximeters or Electrocardiogram devices. Even though these methods offer high reliability, they require the users to have special sensor to measure their heart rate. In this paper we propose a system capable of estimating the heart beat rate using just a camera from a commercially available mobile phone. The advantage of this method is that the user does not need specialized hardware and s/he can take a measurement in virtually any place under almost any circumstances. Moreover the measurement provided can be used as a tool for health coaching applications or effective telecare services aimed in enhancing the user’s well being.},
  eventtitle = {2010 32nd {{Annual International Conference}} of the {{IEEE Engineering}} in {{Medicine}} and {{Biology Society}} ({{EMBC}} 2010)},
  isbn = {978-1-4244-4123-5 978-1-4244-4124-2},
  langid = {english},
  file = {C\:\\Users\\USER\\Zotero\\storage\\RPTXJY6X\\Pelegris et al. - 2010 - A novel method to detect Heart Beat Rate using a m.pdf}
}

@article{PixelRecurrentNeural,
  title = {Pixel {{Recurrent Neural Networks}}},
  pages = {11},
  abstract = {Modeling the distribution of natural images is a landmark problem in unsupervised learning. This task requires an image model that is at once expressive, tractable and scalable. We present a deep neural network that sequentially predicts the pixels in an image along the two spatial dimensions. Our method models the discrete probability of the raw pixel values and encodes the complete set of dependencies in the image. Architectural novelties include fast twodimensional recurrent layers and an effective use of residual connections in deep recurrent networks. We achieve log-likelihood scores on natural images that are considerably better than the previous state of the art. Our main results also provide benchmarks on the diverse ImageNet dataset. Samples generated from the model appear crisp, varied and globally coherent.},
  langid = {english},
  file = {C\:\\Users\\USER\\Zotero\\storage\\YBDTDANT\\Pixel Recurrent Neural Networks.pdf}
}

@inproceedings{prathyushaInnovativeMethodAnalyze2022,
  title = {An {{Innovative Method}} to Analyze the {{Accuracy}} and {{Prediction}} Rate of {{Handwritten Digit Recognition}} with {{Dimensionality Reduction Algorithm}} by Comparing with {{Connectionist Temporal Classification}}},
  booktitle = {2022 14th {{International Conference}} on {{Mathematics}}, {{Actuarial Science}}, {{Computer Science}} and {{Statistics}} ({{MACS}})},
  author = {Prathyusha, Pranathi Sai and Malathi, K. and Pradeep, S.},
  date = {2022-11-12},
  pages = {1--6},
  publisher = {{IEEE}},
  location = {{Karachi, Pakistan}},
  doi = {10.1109/MACS56771.2022.10023068},
  url = {https://ieeexplore.ieee.org/document/10023068/},
  urldate = {2023-07-09},
  abstract = {Recognizing and detecting the digits from the large unbiased data and to find the best accuracy and loss using machine learning algorithms such as Connectionist Temporal Classification (CTC) and innovative Dimensionality Reduction Algorithm (DRA).: Accuracy and Loss are performed with the MNIST dataset from the Keras library. The detection of digits is performed with the Digit’s Dataset. The two groups Connectionist Temporal Classification (N=20) and Dimensionality Reduction Algorithms (N=20). A DRA is used for detecting the novel handwritten digits with the color represented to each digit. The accuracy is analyzed based on identifying the exact digit of 99.90\% where the CTC has the accuracy of 90.84\%. The two machine learning algorithms CNN and CTC are statistically satisfied with the independent sample T-Test (=.001) value (p¡0.05) with a confidence level of 95\%. Conclusion: Recognizing and detecting the handwritten digits significantly satisfied with better accuracy in DRA than in CTC.},
  eventtitle = {2022 14th {{International Conference}} on {{Mathematics}}, {{Actuarial Science}}, {{Computer Science}} and {{Statistics}} ({{MACS}})},
  isbn = {978-1-66546-071-2},
  langid = {english},
  file = {C\:\\Users\\USER\\Zotero\\storage\\FCUMCJGE\\Prathyusha et al. - 2022 - An Innovative Method to analyze the Accuracy and P.pdf}
}

@article{radfordUNSUPERVISEDREPRESENTATIONLEARNING2016,
  title = {{{UNSUPERVISED REPRESENTATION LEARNING WITH DEEP CONVOLUTIONAL GENERATIVE ADVERSARIAL NETWORKS}}},
  author = {Radford, Alec and Metz, Luke and Chintala, Soumith},
  date = {2016},
  pages = {16},
  abstract = {In recent years, supervised learning with convolutional networks (CNNs) has seen huge adoption in computer vision applications. Comparatively, unsupervised learning with CNNs has received less attention. In this work we hope to help bridge the gap between the success of CNNs for supervised learning and unsupervised learning. We introduce a class of CNNs called deep convolutional generative adversarial networks (DCGANs), that have certain architectural constraints, and demonstrate that they are a strong candidate for unsupervised learning. Training on various image datasets, we show convincing evidence that our deep convolutional adversarial pair learns a hierarchy of representations from object parts to scenes in both the generator and discriminator. Additionally, we use the learned features for novel tasks - demonstrating their applicability as general image representations.},
  langid = {english},
  file = {C\:\\Users\\USER\\Zotero\\storage\\LYFCNNEE\\Radford et al. - 2016 - UNSUPERVISED REPRESENTATION LEARNING WITH DEEP CON.pdf}
}

@article{raghuwanshiClassspecificExtremeLearning2018,
  title = {Class-Specific Extreme Learning Machine for Handling Binary Class Imbalance Problem},
  author = {Raghuwanshi, Bhagat Singh and Shukla, Sanyam},
  date = {2018-09},
  journaltitle = {Neural Networks},
  shortjournal = {Neural Networks},
  volume = {105},
  pages = {206--217},
  issn = {08936080},
  doi = {10.1016/j.neunet.2018.05.011},
  url = {https://linkinghub.elsevier.com/retrieve/pii/S0893608018301734},
  urldate = {2022-02-13},
  langid = {english},
  file = {C\:\\Users\\USER\\Zotero\\storage\\TVALXCFT\\Raghuwanshi and Shukla - 2018 - Class-specific extreme learning machine for handli.pdf}
}

@inproceedings{rashidEvaluationHMMBasedTechniques2011,
  title = {An {{Evaluation}} of {{HMM-Based Techniques}} for the {{Recognition}} of {{Screen Rendered Text}}},
  booktitle = {2011 {{International Conference}} on {{Document Analysis}} and {{Recognition}}},
  author = {Rashid, Sheikh Faisal and Shafait, Faisal and Breuel, Thomas M.},
  date = {2011-09},
  pages = {1260--1264},
  publisher = {{IEEE}},
  location = {{Beijing, China}},
  doi = {10.1109/ICDAR.2011.254},
  url = {http://ieeexplore.ieee.org/document/6065512/},
  urldate = {2023-07-15},
  abstract = {Segmentation and recognition of screen rendered text is a challenging task due to its low resolution (72 or 96 ppi) and use of anti-aliased rendering. This paper evaluates Hidden Markov Model (HMM) techniques for OCR of low resolution text–both on screen rendered isolated characters and screen rendered text-lines–and compares it with the performance of other commercial and open source OCR systems. Results show that HMM-based methods reach the performance of other methods on screen rendered text and yield above 98\% character level accuracies on both screen rendered text-lines and characters.},
  eventtitle = {2011 {{International Conference}} on {{Document Analysis}} and {{Recognition}} ({{ICDAR}})},
  isbn = {978-1-4577-1350-7},
  langid = {english},
  file = {C\:\\Users\\USER\\Zotero\\storage\\SK7N5N9V\\Rashid et al. - 2011 - An Evaluation of HMM-Based Techniques for the Reco.pdf}
}

@inproceedings{rawlsHowEfficientlyIncrease2018,
  title = {How {{To Efficiently Increase Resolution}} in {{Neural OCR Models}}},
  booktitle = {2018 {{IEEE}} 2nd {{International Workshop}} on {{Arabic}} and {{Derived Script Analysis}} and {{Recognition}} ({{ASAR}})},
  author = {Rawls, Stephen and Cao, Huaigu and Mathai, Joe and Natarajan, Prem},
  date = {2018-03},
  pages = {140--144},
  publisher = {{IEEE}},
  location = {{London}},
  doi = {10.1109/ASAR.2018.8480182},
  url = {https://ieeexplore.ieee.org/document/8480182/},
  urldate = {2023-06-28},
  abstract = {Modern CRNN OCR models require a fixed line height for all images, and it is known that, up to a point, increasing this input resolution improves recognition performance. However, doing so by simply increasing the line height of input images without changing the CRNN architecture has a large cost in memory and computation (they both scale O(n2) w.r.t. the input line height).},
  eventtitle = {2018 {{IEEE}} 2nd {{International Workshop}} on {{Arabic}} and {{Derived Script Analysis}} and {{Recognition}} ({{ASAR}})},
  isbn = {978-1-5386-1459-4},
  langid = {english},
  file = {C\:\\Users\\USER\\Zotero\\storage\\7YGXAVHK\\Rawls et al. - 2018 - How To Efficiently Increase Resolution in Neural O.pdf}
}

@article{reddyWhatOCR2019,
  title = {What Is an {{OCR}} ??},
  author = {Reddy, Susmith},
  date = {2019-03-25},
  journaltitle = {Towards Data Science},
  url = {https://towardsdatascience.com/what-is-ocr-7d46dc419eb9},
  urldate = {2022-10-05},
  abstract = {The necessity of digitisation is rapidly increasing in the modern era. Due to the growth of information and communication technologies (ICT) and the wide availability of handheld devices, people often prefer digitized content over the printed materials including books and newspaper. Also, it is easier to organize digitized data and analyze them for various purposes with many advanced techniques like artificial intelligence etc. So to keep up with the present technological scenario, it is necessary to convert all the information present till now which is in the printed format to digitised format.}
}

@article{ReportingDiscussingYour,
  title = {Reporting and Discussing Your Findings},
  journaltitle = {Research and Learning Online},
  url = {https://www.monash.edu/rlo/graduate-research-writing/write-the-thesis/writing-the-thesis-chapters/reporting-and-discussing-your-findings},
  urldate = {2022-02-11},
  abstract = {This page deals with the central part of the thesis, where you present the data that forms the basis of your investigation, shaped by the way you have thought about it. In other words, you tell your readers the story that has emerged from your findings. The form of your chapters should be consistent with this story and its components.}
}

@article{rileyMinimumSampleSize2019,
  title = {Minimum Sample Size for Developing a Multivariable Prediction Model: {{Part I}} - {{Continuous}} Outcomes},
  shorttitle = {Minimum Sample Size for Developing a Multivariable Prediction Model},
  author = {Riley, Richard D. and Snell, Kym I.E. and Ensor, Joie and Burke, Danielle L. and Harrell, Frank E. and Moons, Karel G.M. and Collins, Gary S.},
  date = {2019-03-30},
  journaltitle = {Statistics in Medicine},
  shortjournal = {Statistics in Medicine},
  volume = {38},
  number = {7},
  pages = {1262--1275},
  issn = {02776715},
  doi = {10.1002/sim.7993},
  url = {https://onlinelibrary.wiley.com/doi/10.1002/sim.7993},
  urldate = {2022-02-12},
  langid = {english},
  file = {C\:\\Users\\USER\\Zotero\\storage\\WW3J3UEI\\Riley et al. - 2019 - Minimum sample size for developing a multivariable.pdf}
}

@article{robbyImplementationOpticalCharacter2019,
  title = {Implementation of {{Optical Character Recognition}} Using {{Tesseract}} with the {{Javanese Script Target}} in {{Android Application}}},
  author = {Robby, G. Abdul and Tandra, Antonia and Susanto, Imelda and Harefa, Jeklin and Chowanda, Andry},
  date = {2019},
  journaltitle = {Procedia Computer Science},
  shortjournal = {Procedia Computer Science},
  volume = {157},
  pages = {499--505},
  issn = {18770509},
  doi = {10.1016/j.procs.2019.09.006},
  url = {https://linkinghub.elsevier.com/retrieve/pii/S1877050919311640},
  urldate = {2023-06-20},
  abstract = {Abstract Recognising characters from text have been a popular topic in the computer vision area. The application can benefit to many pRreocbolgemnissiinngthcehawraocrtledr.sFforroemxatmexptleh:arveecobgeneinsiangptoepxutlianr dtoopcuicmiennttsh,eclcaosmsipfyuitnegr tvhiesiotenxtaoreras.cTrihpets aopfpdloiccautmioennctsa,nplbaetneerfiect otgonmitiaonny, eptrco.bMlemansyinretsheeawrcohrelrds. Fhaovreexbaemenpldee: vreecloopgendisitnhge tmexetthinoddsocfourmreenctosg, ncliasisnsgifycihnagrathcetetresxitnorbyscurispitnsgoOf dpoticcuaml Cenhtasr,apcltaetre Rreeccooggnniittiioonn, metce.thModasn.yArlethseoaurgchheterxs thraevceogbneietinondepvroelbolpemedutshiengmOepthtiocdasl CfohrarraecctoegrnRiseicnoggnchitaioranchtearssbienenbymuosreinogr OlepssticsoallvCedh,amraocstetrofRtehceoOgnpittiicoanl Cmheathraocdtse.rARlethcoouggnhititoenxtprreocbolgenmitieoxnplporroebdleims buesloinnggOtoptLicaatilnCahlaprhaacbteert Rteexctso.gMnietiaonnwhhaisleb,etehnerme oarree oservleesraslsloalnvgeuda, gmeossht aovfethneonO-pLtaictianl sCchriaprtasctaesr tRheecwogrintitteinontepxrto. bRleemcogexnpislionrgedainsobne-lLonatgintoscLraiptitniaslqpuhiatbeecthteaxlltesn. gMineganaws hthilee,ctohnetroeuarraensdevsehraaplelaonfgtuhaegetesxhtaavree nroelna-tLivaetliyn dsciffrieprtesnatswthiteh wa rLitatteinn tsecxritp. tRteecxot.gTnihsiisngresaenarocnh-Laaimtins tsocrciopltleisctqduaitteascehtsalfloerngOinCgRaisntJhaevacnoenstoeucrhaanradctsehrasp. eAotfottahleotfex5t88ar0ecrhealaraticvteelrys wdieffreerecnotllwecittehdaaLnadtitnrasicnreidptwteixtht.sTehviesrarlesmeaerthchodasimwsittho TceosllseecrtacdtaOtaCseRts tfooorlsO.CTRheinmJoadvealnsetsheecnhbaeraicmteprsle. mAetnotteadl otof 5a8m80obcihlearpahctoenres (wAenredrcooidllebcatseedda).nTd htreahinigedhewstitahccsuevraecrayl(m97e,t5h0o\%ds) wacihthieTveesdsebryactht eOmCoRdteolowlsa.sTahcehimevoeddelbsythceonmbbeiniimngplseimngelnetebdoutondaarmyobboilxefpohrotnhee w(Ahnodleropidarbtsaosefdt)h.eTchhearhaicgtheersatnadccthuerasceypa(9ra7t,e50b\%ou)nadcahryievbeodxebsyinthme aminodbeoldwy aasndacshainevdeadngbayncpoamrtbs.ining single boundary box for the whole parts of the character and the separate boundary boxes in main body and sandangan parts.},
  langid = {english},
  file = {C\:\\Users\\USER\\Zotero\\storage\\ZQWV6X2M\\Robby et al. - 2019 - Implementation of Optical Character Recognition us.pdf}
}

@article{s.AutomaticNumberPlate2018,
  title = {An {{Automatic Number Plate Recognition System}} Using {{OpenCV}} and {{Tesseract OCR Engine}}},
  author = {S., Andrew and Yankey, Jepthah and O., Ernest},
  date = {2018-05-17},
  journaltitle = {International Journal of Computer Applications},
  shortjournal = {IJCA},
  volume = {180},
  number = {43},
  pages = {1--5},
  issn = {09758887},
  doi = {10.5120/ijca2018917150},
  url = {http://www.ijcaonline.org/archives/volume180/number43/agbemenu-2018-ijca-917150.pdf},
  urldate = {2022-09-09},
  abstract = {Automatic Number Plate Recognition (ANPR) is a fairly well explored problem with many successful solutions. However, these solutions are typically tuned towards a particular environment due to the variations in the features of number plates across the world. Algorithms written for number plate recognition are based on these features and so a universal solution would be difficult to realize as the image analysis techniques that are used to build these algorithms cannot themselves boast hundred percent accuracy. The focus of this paper is a proposed algorithm that is optimized to work with Ghanaian vehicle number plates. The algorithm, written in C++ with the OpenCV library, uses edge detection and Feature Detection techniques combined with mathematical morphology for locating the plate. The Tesseract OCR engine was then used to identify the detected characters on the plate.},
  langid = {english},
  file = {C\:\\Users\\USER\\Zotero\\storage\\QN5R7W53\\S. et al. - 2018 - An Automatic Number Plate Recognition System using.pdf}
}

@article{salimansImprovedTechniquesTraining,
  title = {Improved {{Techniques}} for {{Training GANs}}},
  author = {Salimans, Tim and Goodfellow, Ian and Zaremba, Wojciech and Cheung, Vicki and Radford, Alec and Chen, Xi and Chen, Xi},
  pages = {9},
  abstract = {We present a variety of new architectural features and training procedures that we apply to the generative adversarial networks (GANs) framework. Using our new techniques, we achieve state-of-the-art results in semi-supervised classification on MNIST, CIFAR-10 and SVHN. The generated images are of high quality as confirmed by a visual Turing test: our model generates MNIST samples that humans cannot distinguish from real data, and CIFAR-10 samples that yield a human error rate of 21.3\%. We also present ImageNet samples with unprecedented resolution and show that our methods enable the model to learn recognizable features of ImageNet classes.},
  langid = {english},
  file = {C\:\\Users\\USER\\Zotero\\storage\\SG7S59PF\\Salimans et al. - Improved Techniques for Training GANs.pdf}
}

@article{salimansImprovedTechniquesTraininga,
  title = {Improved {{Techniques}} for {{Training GANs}}},
  author = {Salimans, Tim and Goodfellow, Ian and Zaremba, Wojciech and Cheung, Vicki and Radford, Alec and Chen, Xi and Chen, Xi},
  pages = {9},
  abstract = {We present a variety of new architectural features and training procedures that we apply to the generative adversarial networks (GANs) framework. Using our new techniques, we achieve state-of-the-art results in semi-supervised classification on MNIST, CIFAR-10 and SVHN. The generated images are of high quality as confirmed by a visual Turing test: our model generates MNIST samples that humans cannot distinguish from real data, and CIFAR-10 samples that yield a human error rate of 21.3\%. We also present ImageNet samples with unprecedented resolution and show that our methods enable the model to learn recognizable features of ImageNet classes.},
  langid = {english}
}

@article{schaarschmidtAutomatedPolyglotPersistence,
  title = {Towards {{Automated Polyglot Persistence}}},
  author = {Schaarschmidt, Michael and Gessert, Felix and Ritter, Norbert},
  pages = {10},
  abstract = {In this paper, we present an innovative solution for providing automated polyglot persistence based on service level agreements defined over functional and non-functional requirements of database systems. Complex applications require polyglot persistence to deal with a wide range of database related needs. Until now, the overhead and the required know-how to manage multiple database systems prevents many applications from employing efficient polyglot persistence solutions. Instead, developers are often forced to implement one-size-fits-all solutions that do not scale well and cannot easily be upgraded. Therefore, we introduce the concept for a Polyglot Persistence Mediator (PPM), which allows for runtime decisions on routing data to different backends according to schema-based annotations. This enables applications to either employ polyglot persistence right from the beginning or employ new systems at any point with minimal overhead. We have implemented and evaluated the concept of automated polyglot persistence for a REST-based Database-as-a-Service setting. Evaluations were performed on various EC2 setups, showing a scalable writeperformance increase of 50-100\% for a typical polyglot persistence scenario as well as drastically reduced latencies for reads and queries.},
  langid = {english},
  file = {C\:\\Users\\USER\\Zotero\\storage\\GSIWZVYZ\\Schaarschmidt et al. - Towards Automated Polyglot Persistence.pdf}
}

@article{schroerSystematicLiteratureReview2021,
  title = {A {{Systematic Literature Review}} on {{Applying CRISP-DM Process Model}}},
  author = {Schröer, Christoph and Kruse, Felix and Gómez, Jorge Marx},
  date = {2021},
  journaltitle = {Procedia Computer Science},
  shortjournal = {Procedia Computer Science},
  volume = {181},
  pages = {526--534},
  issn = {18770509},
  doi = {10.1016/j.procs.2021.01.199},
  url = {https://linkinghub.elsevier.com/retrieve/pii/S1877050921002416},
  urldate = {2022-09-09},
  abstract = {Abstract CRISP-DM is the de-facto standard and an industry-independent process model for applying data mining projects. Twenty years aCfRteIrSiPts-DreMleaissethine2d0e0-f0a,cwtoe swtaonudldarldikaentdoapnroinvdiduestarys-yisntdeempaetnicdelintet rpartoucreesrsevmieowdeol fforercaepnptlsytiundgiedsaptaubmliisnhinedg ipnroIEjeEcEts,. STcwieenncteyDyieraercst aafntderAitCs Mrelaebasoeutind2at0a0m0,iwniengwuosueldclaiskeestaoppprloyvinidgeCaRsyISsPte-mDaMtic. Wliteergaitvuerearnevoiveewrvoifewrecoefntthseturdesieesarpcuhbfloischuesd, cinurIrEeEnEt m, SecthieondcoelDogirieecst, abnedst AprCaMcticaebsouant ddaptoasmsiibnlienggaupsseincacsoensdaupcptliynigngthCe RsiIxSPph-DasMes. oWf eCgRiIvSePa-nDoMv.eTrvhieewmoafinthfeinrdeisnegasrcahrefothcauts,CcRuIrSrePn-tDmMetihsosdtoillloagidees-, bfaecsttoprrsatcatnidceasrdaninddpaotassmibilneingga,pbsuint tchoenreduarceticnhgatlhleensgiexspshinacseesthoef mCRosItSsPtu-DdiMes.dTohneomt faoinrefsienedaindgespaloreymtheanttCpRhaISseP.-TDhMe cisonsttrililbuatidoenfoafctoourrstpaanpdearrdisintodaidtaenmtiifnyinbge, sbtupt rtahcetrieceasreacnhdalpleroncgeessssipnhcaestehseimn owsthsictuhddieastadomniontinfgoreasneaelyastdsepcalonymbeenbteptthearsesu. pTphoercteodn.trFibuurttihoenr ocof notruirbuptaiopnerisisa ttoemidpelantteiffyorbsetsrtucptruarcitnicgeasnadnrdelpearosicnegssCpRhIaSsPe-sDiMn wsthuidcihesd. ata mining analysts can be better supported. Further contribution is a template for structuring and releasing CRISP-DM studies.},
  langid = {english},
  file = {C\:\\Users\\USER\\Zotero\\storage\\SACEUQAX\\Schröer et al. - 2021 - A Systematic Literature Review on Applying CRISP-D.pdf}
}

@article{schroerSystematicLiteratureReview2021a,
  title = {A {{Systematic Literature Review}} on {{Applying CRISP-DM Process Model}}},
  author = {Schröer, Christoph and Kruse, Felix and Gómez, Jorge Marx},
  date = {2021},
  journaltitle = {Procedia Computer Science},
  shortjournal = {Procedia Computer Science},
  volume = {181},
  pages = {526--534},
  issn = {18770509},
  doi = {10.1016/j.procs.2021.01.199},
  url = {https://linkinghub.elsevier.com/retrieve/pii/S1877050921002416},
  urldate = {2022-10-05},
  abstract = {Abstract CRISP-DM is the de-facto standard and an industry-independent process model for applying data mining projects. Twenty years aCfRteIrSiPts-DreMleaissethine2d0e0-f0a,cwtoe swtaonudldarldikaentdoapnroinvdiduestarys-yisntdeempaetnicdelintet rpartoucreesrsevmieowdeol fforercaepnptlsytiundgiedsaptaubmliisnhinedg ipnroIEjeEcEts,. STcwieenncteyDyieraercst aafntderAitCs Mrelaebasoeutind2at0a0m0,iwniengwuosueldclaiskeestaoppprloyvinidgeCaRsyISsPte-mDaMtic. Wliteergaitvuerearnevoiveewrvoifewrecoefntthseturdesieesarpcuhbfloischuesd, cinurIrEeEnEt m, SecthieondcoelDogirieecst, abnedst AprCaMcticaebsouant ddaptoasmsiibnlienggaupsseincacsoensdaupcptliynigngthCe RsiIxSPph-DasMes. oWf eCgRiIvSePa-nDoMv.eTrvhieewmoafinthfeinrdeisnegasrcahrefothcauts,CcRuIrSrePn-tDmMetihsosdtoillloagidees-, bfaecsttoprrsatcatnidceasrdaninddpaotassmibilneingga,pbsuint tchoenreduarceticnhgatlhleensgiexspshinacseesthoef mCRosItSsPtu-DdiMes.dTohneomt faoinrefsienedaindgespaloreymtheanttCpRhaISseP.-TDhMe cisonsttrililbuatidoenfoafctoourrstpaanpdearrdisintodaidtaenmtiifnyinbge, sbtupt rtahcetrieceasreacnhdalpleroncgeessssipnhcaestehseimn owsthsictuhddieastadomniontinfgoreasneaelyastdsepcalonymbeenbteptthearsesu. pTphoercteodn.trFibuurttihoenr ocof notruirbuptaiopnerisisa ttoemidpelantteiffyorbsetsrtucptruarcitnicgeasnadnrdelpearosicnegssCpRhIaSsPe-sDiMn wsthuidcihesd. ata mining analysts can be better supported. Further contribution is a template for structuring and releasing CRISP-DM studies.},
  langid = {english},
  file = {C\:\\Users\\USER\\Zotero\\storage\\E296B9FR\\Schröer et al. - 2021 - A Systematic Literature Review on Applying CRISP-D.pdf}
}

@article{shalaIndoorPositioningUsing,
  title = {Indoor {{Positioning}} Using {{Sensor-fusion}} in {{Android Devices}}},
  author = {Shala, Ubejd and Rodriguez, Angel and Frisk, Fredrik and Klonowska, Kamilla},
  pages = {58},
  abstract = {This project examines the level of accuracy that can be achieved in precision positioning by using built-in sensors in an Android smartphone. The project is focused in estimating the position of the phone inside a building where the GPS signal is bad or unavailable. The approach is sensor-fusion: by using data from the device’s different sensors, such as accelerometer, gyroscope and wireless adapter, the position is determined. The results show that the technique is promising for future handheld indoor navigation systems that can be used in malls, museums, large office buildings, hospitals, etc.},
  langid = {english},
  file = {C\:\\Users\\USER\\Zotero\\storage\\SNKY76UM\\Shala et al. - Indoor Positioning using Sensor-fusion in Android .pdf}
}

@online{shibsankarGANArchitecturesYou2022,
  title = {6 {{GAN Architectures You Really Should Know}}},
  author = {Shibsankar, Das},
  date = {2022-03-21},
  url = {https://neptune.ai/blog/6-gan-architectures},
  urldate = {2022-05-25},
  abstract = {Generative Adversarial Networks (GANs) were first introduced in 2014 by Ian Goodfellow et. al. and since then this topic itself opened up a new area of research. Within a few years, the research community came up with plenty of papers on this topic some of which have very interesting names :). You have CycleGAN, followed by BiCycleGAN, followed by ReCycleGAN and so on. With the invention of GANs, Generative Models had started showing promising results in generating realistic images. GANs has shown tremendous success in Computer Vision. In recent times, it started showing promising results in Audio, Text as well.},
  organization = {{Neptune Blog}}
}

@article{shindeUsingCRNNPerform2021,
  title = {Using {{CRNN}} to {{Perform OCR}} over {{Forms}}},
  author = {Shinde, Siddhesh and Saraiya, Tanmey and Jain, Jayesh and Narvekar, Chhaya},
  date = {2021},
  journaltitle = {International Journal of Engineering Research},
  volume = {9},
  number = {3},
  abstract = {In digitization, most of the documents, especially the forms are filled and processed online to speed up the process. But one such organization, Indian Railways, has a process of filling out offline forms for ticket booking. This process is very time-consuming as it requires an attendee to check the form and enter the details into the database. To speed up this process, Optical Character Recognition(OCR) is a very viable option for this case. This paper presents a structured process of locating input fields on the form, scanning the input data, processing the data and entering the data to the final database. We use CRNN(Convolutional Recurrent Neural Network) model to perform OCR on the user’s handwritten input. This automated system aims at reducing the waiting time of the current system being used.},
  langid = {english},
  file = {C\:\\Users\\USER\\Zotero\\storage\\HISSD4ZJ\\Shinde et al. - 2021 - Using CRNN to Perform OCR over Forms.pdf}
}

@online{simonyanVeryDeepConvolutional2015,
  title = {Very {{Deep Convolutional Networks}} for {{Large-Scale Image Recognition}}},
  author = {Simonyan, Karen and Zisserman, Andrew},
  date = {2015-04-10},
  eprint = {1409.1556},
  eprinttype = {arxiv},
  eprintclass = {cs},
  url = {http://arxiv.org/abs/1409.1556},
  urldate = {2022-09-09},
  abstract = {In this work we investigate the effect of the convolutional network depth on its accuracy in the large-scale image recognition setting. Our main contribution is a thorough evaluation of networks of increasing depth using an architecture with very small (3 × 3) convolution filters, which shows that a significant improvement on the prior-art configurations can be achieved by pushing the depth to 16–19 weight layers. These findings were the basis of our ImageNet Challenge 2014 submission, where our team secured the first and the second places in the localisation and classification tracks respectively. We also show that our representations generalise well to other datasets, where they achieve state-of-the-art results. We have made our two best-performing ConvNet models publicly available to facilitate further research on the use of deep visual representations in computer vision.},
  langid = {english},
  pubstate = {preprint},
  keywords = {Computer Science - Computer Vision and Pattern Recognition},
  file = {C\:\\Users\\USER\\Zotero\\storage\\QX8JMPGP\\Simonyan and Zisserman - 2015 - Very Deep Convolutional Networks for Large-Scale I.pdf}
}

@inproceedings{smithOverviewTesseractOCR2007,
  title = {An {{Overview}} of the {{Tesseract OCR Engine}}},
  booktitle = {Ninth {{International Conference}} on {{Document Analysis}} and {{Recognition}} ({{ICDAR}} 2007) {{Vol}} 2},
  author = {Smith, R.},
  date = {2007-09},
  pages = {629--633},
  publisher = {{IEEE}},
  location = {{Curitiba, Parana, Brazil}},
  issn = {1520-5363},
  doi = {10.1109/ICDAR.2007.4376991},
  url = {http://ieeexplore.ieee.org/document/4376991/},
  urldate = {2022-09-09},
  abstract = {The Tesseract OCR engine, as was the HP Research Prototype in the UNLV Fourth Annual Test of OCR Accuracy[1], is described in a comprehensive overview. Emphasis is placed on aspects that are novel or at least unusual in an OCR engine, including in particular the line finding, features/classification methods, and the adaptive classifier.},
  eventtitle = {Ninth {{International Conference}} on {{Document Analysis}} and {{Recognition}} ({{ICDAR}} 2007) {{Vol}} 2},
  isbn = {978-0-7695-2822-9},
  langid = {english},
  file = {C\:\\Users\\USER\\Zotero\\storage\\5H6QBKHJ\\Smith - 2007 - An Overview of the Tesseract OCR Engine.pdf}
}

@article{spasicCulturalBackgroundMeaning,
  title = {Cultural\_{{Background}}\_and\_{{Meaning}}\_of\_{{Ta}}\_{{Moko}}},
  author = {Spasic, Katerina},
  pages = {45},
  abstract = {The objective of this bachelor thesis is to study the origin and history of Māori tattoos and its influence on tattooing nowadays. The main aim is to discover the cultural meaning of tattoos called moko by exploring Māori legends and their spiritual life. It deals with questions such as: Why do Māori use them? How do these tattoos contribute to Māori personal identification with their own culture and traditions? And what significance and psychological meaning do they have? This work includes three parts. The first section approaches history and Māori legends and consequently the original significance of this art. The second part focuses on tattoos in the present era and their psychological meanings nowadays and it also takes into consideration modern wearers of this tattoo and artists. The conclusion summarizes and comments on possible explanations resulting from the study.},
  langid = {english},
  file = {C\:\\Users\\USER\\Zotero\\storage\\UTXKWG93\\Spasic - Cultural_Background_and_Meaning_of_Ta_Moko.pdf}
}

@misc{spssMissingDataHidden,
  title = {Missing Data: The Hidden Problem},
  author = {SPSS},
  publisher = {{APSS}},
  abstract = {Just about everyone doing analysis has some missing data, especially survey researchers, market researchers, database analysts, researchers and social scientists. Missing data are questions without answers or variables without observations. Even a small percent of missing data can cause serious problems with your analysis leading you to draw wrong conclusions. This white paper presents a case study demonstrating how missing data can affect your analysis and the decisions you make based on your results. It uses SPSS Missing Value Analysis to overcome a missing data problem to make better decisions.},
  file = {C\:\\Users\\USER\\Zotero\\storage\\P6MKZHHJ\\2.pdf}
}

@article{stachowiakDetectionPredictionOsteoarthritis2016,
  title = {Detection and Prediction of Osteoarthritis in Knee and Hand Joints Based on the {{X-ray}} Image Analysis},
  author = {Stachowiak, G.W. and Wolski, M. and Woloszynski, T. and Podsiadlo, P.},
  date = {2016-12},
  journaltitle = {Biosurface and Biotribology},
  shortjournal = {Biosurface and Biotribology},
  volume = {2},
  number = {4},
  pages = {162--172},
  issn = {24054518},
  doi = {10.1016/j.bsbt.2016.11.004},
  url = {https://linkinghub.elsevier.com/retrieve/pii/S2405451816300393},
  urldate = {2022-04-02},
  abstract = {Current assessment of osteoarthritis (OA) is primary based on visual grading of joint space narrowing and osteophytes present on radiographs. The approach is observer-dependent, not sensitive enough for the detection of the early stages of OA and time consuming. A promising solution is through fractal analysis of trabecular bone (TB) textures on radiographs. The goal is to develop an automated decision support system for the detection and prediction of OA based on TB texture regions selected on knee and hand radiographs. In this review, we describe our progress towards this development which was conducted in five stages, i.e., (i) development of automated methods for the selection of TB texture regions on knee and hand radiographs (ii), development of fractal signature methods for TB texture analysis, (iii) applications of the methods in the analysis of x-ray images of knees and hands, (iv) development of TB texture classification system, and (v) development of ReadMyXray website for knee x-ray analysis. The results achieved so far are encouraging and it is hoped, that once the system is fully developed and evaluated, it will be used to aid medical practitioners in the decision-making, i.e., in designing OA preventative measures, treatments and monitoring the OA progression.},
  langid = {english},
  file = {C\:\\Users\\USER\\Zotero\\storage\\5URB8FN2\\Stachowiak et al. - 2016 - Detection and prediction of osteoarthritis in knee.pdf}
}

@book{sydenhamHandbookMeasuringSystem2005,
  title = {Handbook of Measuring System Design},
  editor = {Sydenham, P. H. and Thorn, Richard},
  date = {2005},
  publisher = {{Wiley}},
  location = {{Chichester, England}},
  isbn = {978-0-470-02143-9},
  langid = {english},
  pagetotal = {3},
  keywords = {{Handbooks, manuals, etc},Measurement},
  file = {C\:\\Users\\USER\\Zotero\\storage\\PYIH2UW5\\Sydenham and Thorn - 2005 - Handbook of measuring system design.pdf}
}

@online{szegedyGoingDeeperConvolutions2014,
  title = {Going {{Deeper}} with {{Convolutions}}},
  author = {Szegedy, Christian and Liu, Wei and Jia, Yangqing and Sermanet, Pierre and Reed, Scott and Anguelov, Dragomir and Erhan, Dumitru and Vanhoucke, Vincent and Rabinovich, Andrew},
  date = {2014-09-16},
  eprint = {1409.4842},
  eprinttype = {arxiv},
  eprintclass = {cs},
  url = {http://arxiv.org/abs/1409.4842},
  urldate = {2022-09-09},
  abstract = {We propose a deep convolutional neural network architecture codenamed Inception, which was responsible for setting the new state of the art for classification and detection in the ImageNet Large-Scale Visual Recognition Challenge 2014 (ILSVRC14). The main hallmark of this architecture is the improved utilization of the computing resources inside the network. This was achieved by a carefully crafted design that allows for increasing the depth and width of the network while keeping the computational budget constant. To optimize quality, the architectural decisions were based on the Hebbian principle and the intuition of multi-scale processing. One particular incarnation used in our submission for ILSVRC14 is called GoogLeNet, a 22 layers deep network, the quality of which is assessed in the context of classification and detection.},
  langid = {english},
  pubstate = {preprint},
  keywords = {Computer Science - Computer Vision and Pattern Recognition},
  file = {C\:\\Users\\USER\\Zotero\\storage\\YP9WXWZF\\Szegedy et al. - 2014 - Going Deeper with Convolutions.pdf}
}

@article{teamcounterpointINFOGRAPHICQ220212021,
  title = {{{INFOGRAPHIC}}: {{Q2}} 2021 | {{MOBILE MARKET MONITOR}}},
  author = {Team Counterpoint},
  date = {2021-09-20},
  journaltitle = {counterpointsearch.com},
  url = {https://www.counterpointresearch.com/infographic-q2-2021/},
  abstract = {Our Q2 2021 Market Monitor report has been published. We release one infographic each quarter to summarize the mobile handset market activities in a single page. Some quick observations on the smartphone market:}
}

@article{vancalsterCalibrationHierarchyRisk2016,
  title = {A Calibration Hierarchy for Risk Models Was Defined: From Utopia to Empirical Data},
  shorttitle = {A Calibration Hierarchy for Risk Models Was Defined},
  author = {Van Calster, Ben and Nieboer, Daan and Vergouwe, Yvonne and De Cock, Bavo and Pencina, Michael J. and Steyerberg, Ewout W.},
  date = {2016-06},
  journaltitle = {Journal of Clinical Epidemiology},
  shortjournal = {Journal of Clinical Epidemiology},
  volume = {74},
  pages = {167--176},
  issn = {08954356},
  doi = {10.1016/j.jclinepi.2015.12.005},
  url = {https://linkinghub.elsevier.com/retrieve/pii/S0895435615005818},
  urldate = {2022-02-12},
  abstract = {Objective: Calibrated risk models are vital for valid decision support. We define four levels of calibration and describe implications for model development and external validation of predictions. Study Design and Setting: We present results based on simulated data sets. Results: A common definition of calibration is ‘‘having an event rate of R\% among patients with a predicted risk of R\%,’’ which we refer to as ‘‘moderate calibration.’’ Weaker forms of calibration only require the average predicted risk (mean calibration) or the average prediction effects (weak calibration) to be correct. ‘‘Strong calibration’’ requires that the event rate equals the predicted risk for every covariate pattern. This implies that the model is fully correct for the validation setting. We argue that this is unrealistic: the model type may be incorrect, the linear predictor is only asymptotically unbiased, and all nonlinear and interaction effects should be correctly modeled. In addition, we prove that moderate calibration guarantees nonharmful decision making. Finally, results indicate that a flexible assessment of calibration in small validation data sets is problematic. Conclusion: Strong calibration is desirable for individualized decision support but unrealistic and counter productive by stimulating the development of overly complex models. Model development and external validation should focus on moderate calibration. Ó 2016 Elsevier Inc. All rights reserved.},
  langid = {english},
  file = {C\:\\Users\\USER\\Zotero\\storage\\L7SALVCQ\\Van Calster et al. - 2016 - A calibration hierarchy for risk models was define.pdf}
}

@article{vancalsterCalibrationHierarchyRisk2016a,
  title = {A Calibration Hierarchy for Risk Models Was Defined: From Utopia to Empirical Data},
  shorttitle = {A Calibration Hierarchy for Risk Models Was Defined},
  author = {Van Calster, Ben and Nieboer, Daan and Vergouwe, Yvonne and De Cock, Bavo and Pencina, Michael J. and Steyerberg, Ewout W.},
  date = {2016-06},
  journaltitle = {Journal of Clinical Epidemiology},
  shortjournal = {Journal of Clinical Epidemiology},
  volume = {74},
  pages = {167--176},
  issn = {08954356},
  doi = {10.1016/j.jclinepi.2015.12.005},
  url = {https://linkinghub.elsevier.com/retrieve/pii/S0895435615005818},
  urldate = {2022-02-12},
  abstract = {Objective: Calibrated risk models are vital for valid decision support. We define four levels of calibration and describe implications for model development and external validation of predictions. Study Design and Setting: We present results based on simulated data sets. Results: A common definition of calibration is ‘‘having an event rate of R\% among patients with a predicted risk of R\%,’’ which we refer to as ‘‘moderate calibration.’’ Weaker forms of calibration only require the average predicted risk (mean calibration) or the average prediction effects (weak calibration) to be correct. ‘‘Strong calibration’’ requires that the event rate equals the predicted risk for every covariate pattern. This implies that the model is fully correct for the validation setting. We argue that this is unrealistic: the model type may be incorrect, the linear predictor is only asymptotically unbiased, and all nonlinear and interaction effects should be correctly modeled. In addition, we prove that moderate calibration guarantees nonharmful decision making. Finally, results indicate that a flexible assessment of calibration in small validation data sets is problematic. Conclusion: Strong calibration is desirable for individualized decision support but unrealistic and counter productive by stimulating the development of overly complex models. Model development and external validation should focus on moderate calibration. Ó 2016 Elsevier Inc. All rights reserved.},
  langid = {english},
  file = {C\:\\Users\\USER\\Zotero\\storage\\LDVSWM76\\Van Calster et al. - 2016 - A calibration hierarchy for risk models was define.pdf}
}

@article{vanderploegModernModellingTechniques2014,
  title = {Modern Modelling Techniques Are Data Hungry: A Simulation Study for Predicting Dichotomous Endpoints},
  shorttitle = {Modern Modelling Techniques Are Data Hungry},
  author = {family=Ploeg, given=Tjeerd, prefix=van der, useprefix=true and Austin, Peter C and Steyerberg, Ewout W},
  date = {2014-12},
  journaltitle = {BMC Medical Research Methodology},
  shortjournal = {BMC Med Res Methodol},
  volume = {14},
  number = {1},
  pages = {137},
  issn = {1471-2288},
  doi = {10.1186/1471-2288-14-137},
  url = {https://bmcmedresmethodol.biomedcentral.com/articles/10.1186/1471-2288-14-137},
  urldate = {2022-02-12},
  abstract = {Background: Modern modelling techniques may potentially provide more accurate predictions of binary outcomes than classical techniques. We aimed to study the predictive performance of different modelling techniques in relation to the effective sample size (“data hungriness”). Methods: We performed simulation studies based on three clinical cohorts: 1282 patients with head and neck cancer (with 46.9\% 5 year survival), 1731 patients with traumatic brain injury (22.3\% 6 month mortality) and 3181 patients with minor head injury (7.6\% with CT scan abnormalities). We compared three relatively modern modelling techniques: support vector machines (SVM), neural nets (NN), and random forests (RF) and two classical techniques: logistic regression (LR) and classification and regression trees (CART). We created three large artificial databases with 20 fold, 10 fold and 6 fold replication of subjects, where we generated dichotomous outcomes according to different underlying models. We applied each modelling technique to increasingly larger development parts (100 repetitions). The area under the ROC-curve (AUC) indicated the performance of each model in the development part and in an independent validation part. Data hungriness was defined by plateauing of AUC and small optimism (difference between the mean apparent AUC and the mean validated AUC {$<$}0.01). Results: We found that a stable AUC was reached by LR at approximately 20 to 50 events per variable, followed by CART, SVM, NN and RF models. Optimism decreased with increasing sample sizes and the same ranking of techniques. The RF, SVM and NN models showed instability and a high optimism even with {$>$}200 events per variable. Conclusions: Modern modelling techniques such as SVM, NN and RF may need over 10 times as many events per variable to achieve a stable AUC and a small optimism than classical modelling techniques such as LR. This implies that such modern techniques should only be used in medical prediction problems if very large data sets are available.},
  langid = {english}
}

@article{vermaUnderstanding1D3D2019,
  title = {Understanding {{1D}} and {{3D Convolution Neural Network}} | {{Keras}}},
  author = {Verma, Shiva},
  date = {2019-09-20},
  journaltitle = {Towards Data Science},
  url = {https://towardsdatascience.com/understanding-1d-and-3d-convolution-neural-network-keras-9d8f76e29610},
  abstract = {When we say Convolution Neural Network (CNN), generally we refer to a 2 dimensional CNN which is used for image classification. But there are two other types of Convolution Neural Networks used in the real world, which are 1 dimensional and 3-dimensional CNNs. In this guide, we are going to cover 1D and 3D CNNs and their applications in the real world. I am assuming you are already familiar with the concept of Convolutions Networks in general.}
}

@online{walesBayWheels,
  type = {Wikipedia},
  title = {Bay {{Wheels}}},
  author = {Wales, Jimmy},
  url = {https://en.wikipedia.org/wiki/Bay_Wheels},
  abstract = {Bay Wheels is a regional public bicycle sharing system in California's San Francisco Bay Area. It is operated by Motivate in a partnership with the Metropolitan Transportation Commission and the Bay Area Air Quality Management District.[3] Bay Wheels is 'the first regional and large-scale bicycle sharing system deployed in California and on the West Coast of the United States. It was established as Bay Area}
}

@article{woloszynskiSignatureDissimilarityMeasure2010,
  title = {A Signature Dissimilarity Measure for Trabecular Bone Texture in Knee Radiographs: {{A}} Signature Dissimilarity Measure},
  shorttitle = {A Signature Dissimilarity Measure for Trabecular Bone Texture in Knee Radiographs},
  author = {Woloszynski, T. and Podsiadlo, P. and Stachowiak, G. W. and Kurzynski, M.},
  date = {2010-04-14},
  journaltitle = {Medical Physics},
  shortjournal = {Med. Phys.},
  volume = {37},
  number = {5},
  pages = {2030--2042},
  issn = {00942405},
  doi = {10.1118/1.3373522},
  url = {http://doi.wiley.com/10.1118/1.3373522},
  urldate = {2022-04-02},
  abstract = {Purpose: The purpose of this study is to develop a dissimilarity measure for the classification of trabecular bone ͑TB͒ texture in knee radiographs. Problems associated with the traditional extraction and selection of texture features and with the invariance to imaging conditions such as image size, anisotropy, noise, blur, exposure, magnification, and projection angle were addressed. Methods: In the method developed, called a signature dissimilarity measure ͑SDM͒, a sum of earth mover’s distances calculated for roughness and orientation signatures is used to quantify dissimilarities between textures. Scale-space theory was used to ensure scale and rotation invariance. The effects of image size, anisotropy, noise, and blur on the SDM developed were studied using computer generated fractal texture images. The invariance of the measure to image exposure, magnification, and projection angle was studied using x-ray images of human tibia head. For the studies, Mann–Whitney tests with significance level of 0.01 were used. A comparison study between the performances of a SDM based classification system and other two systems in the classification of Brodatz textures and the detection of knee osteoarthritis ͑OA͒ were conducted. The other systems are based on weighted neighbor distance using compound hierarchy of algorithms representing morphology ͑WND-CHARM͒ and local binary patterns ͑LBP͒. Results: Results obtained indicate that the SDM developed is invariant to image exposure ͑2.5–30 mA s͒, magnification ͑ϫ1.00– ϫ 1.35͒, noise associated with film graininess and quantum mottle ͑Ͻ25\%͒, blur generated by a sharp film screen, and image size ͑Ͼ64ϫ 64 pixels͒. However, the measure is sensitive to changes in projection angle ͑Ͼ5°͒, image anisotropy ͑Ͼ30°͒, and blur generated by a regular film screen. For the classification of Brodatz textures, the SDM based system produced comparable results to the LBP system. For the detection of knee OA, the SDM based system achieved 78.8\% classification accuracy and outperformed the WND-CHARM system ͑64.2\%͒. Conclusions: The SDM is well suited for the classification of TB texture images in knee OA detection and may be useful for the texture classification of medical images in general. © 2010 American Association of Physicists in Medicine. ͓DOI: 10.1118/1.3373522͔},
  langid = {english},
  file = {C\:\\Users\\USER\\Zotero\\storage\\4AZS2TVA\\Woloszynski et al. - 2010 - A signature dissimilarity measure for trabecular b.pdf}
}

@article{wuComputeraidedDiagnosisEarly2014,
  title = {Computer-Aided Diagnosis of Early Knee Osteoarthritis Based on {{MRI T2}} Mapping},
  author = {Wu, Yixiao and Yang, Ran and Jia, Sen and Li, Zhanjun and Zhou, Zhiyang and Lou, Ting},
  date = {2014},
  journaltitle = {Bio-Medical Materials and Engineering},
  volume = {24},
  number = {6},
  pages = {3379--3388},
  issn = {09592989, 18783619},
  doi = {10.3233/BME-141161},
  url = {https://www.medra.org/servlet/aliasResolver?alias=iospress&doi=10.3233/BME-141161},
  urldate = {2022-04-02},
  abstract = {This work was aimed at studying the method of computer-aided diagnosis of early knee OA (OA: osteoarthritis). Based on the technique of MRI (MRI: Magnetic Resonance Imaging) T2 Mapping, through computer image processing, feature extraction, calculation and analysis via constructing a classifier, an effective computer-aided diagnosis method for knee OA was created to assist doctors in their accurate, timely and convenient detection of potential risk of OA. In order to evaluate this method, a total of 1380 data from the MRI images of 46 samples of knee joints were collected. These data were then modeled through linear regression on an offline general platform by the use of the ImageJ software, and a map of the physical parameter T2 was reconstructed. After the image processing, the T2 values of ten regions in the WORMS (WORMS: Whole-organ Magnetic Resonance Imaging Score) areas of the articular cartilage were extracted to be used as the eigenvalues in data mining. Then, a RBF (RBF: Radical Basis Function) network classifier was built to classify and identify the collected data. The classifier exhibited a final identification accuracy of 75\%, indicating a good result of assisting diagnosis. Since the knee OA classifier constituted by a weights-directly-determined RBF neural network didn’t require any iteration, our results demonstrated that the optimal weights, appropriate center and variance could be yielded through simple procedures. Furthermore, the accuracy for both the training samples and the testing samples from the normal group could reach 100\%. Finally, the classifier was superior both in time efficiency and classification performance to the frequently used classifiers based on iterative learning. Thus it was suitable to be used as an aid to computer-aided diagnosis of early knee OA.},
  langid = {english},
  file = {C\:\\Users\\USER\\Zotero\\storage\\87N79MWL\\Wu et al. - 2014 - Computer-aided diagnosis of early knee osteoarthri.pdf}
}

@article{wuIntroductionConvolutionalNeural,
  title = {Introduction to {{Convolutional Neural Networks}}},
  author = {Wu, Jianxin},
  pages = {31},
  langid = {english},
  file = {C\:\\Users\\USER\\Zotero\\storage\\SQB8759V\\Wu - Introduction to Convolutional Neural Networks.pdf}
}

@article{wynantsPredictionModelsDiagnosis2020,
  title = {Prediction Models for Diagnosis and Prognosis of Covid-19: Systematic Review and Critical Appraisal},
  shorttitle = {Prediction Models for Diagnosis and Prognosis of Covid-19},
  author = {Wynants, Laure and Van Calster, Ben and Collins, Gary S and Riley, Richard D and Heinze, Georg and Schuit, Ewoud and Bonten, Marc M J and Dahly, Darren L and Damen, Johanna A and Debray, Thomas P A and family=Jong, given=Valentijn M T, prefix=de, useprefix=true and De Vos, Maarten and Dhiman, Paula and Haller, Maria C and Harhay, Michael O and Henckaerts, Liesbet and Heus, Pauline and Kammer, Michael and Kreuzberger, Nina and Lohmann, Anna and Luijken, Kim and Ma, Jie and Martin, Glen P and McLernon, David J and Andaur Navarro, Constanza L and Reitsma, Johannes B and Sergeant, Jamie C and Shi, Chunhu and Skoetz, Nicole and Smits, Luc J M and Snell, Kym I E and Sperrin, Matthew and Spijker, René and Steyerberg, Ewout W and Takada, Toshihiko and Tzoulaki, Ioanna and family=Kuijk, given=Sander M J, prefix=van, useprefix=true and family=Bussel, given=Bas C T, prefix=van, useprefix=true and family=Horst, given=Iwan C C, prefix=van der, useprefix=true and family=Royen, given=Florien S, prefix=van, useprefix=true and Verbakel, Jan Y and Wallisch, Christine and Wilkinson, Jack and Wolff, Robert and Hooft, Lotty and Moons, Karel G M and family=Smeden, given=Maarten, prefix=van, useprefix=true},
  date = {2020-04-07},
  journaltitle = {BMJ},
  shortjournal = {BMJ},
  pages = {m1328},
  issn = {1756-1833},
  doi = {10.1136/bmj.m1328},
  url = {https://www.bmj.com/lookup/doi/10.1136/bmj.m1328},
  urldate = {2022-02-12},
  abstract = {OBJECTIVE To review and appraise the validity and usefulness of published and preprint reports of prediction models for diagnosing coronavirus disease 2019 (covid-19) in patients with suspected infection, for prognosis of patients with covid-19, and for detecting people in the general population at increased risk of becoming infected with covid-19 or being admitted to hospital with the disease. DESIGN Living systematic review and critical appraisal by the COVID-PRECISE (Precise Risk Estimation to optimise covid-19 Care for Infected or Suspected patients in diverse sEttings) group. DATA SOURCES PubMed and Embase through Ovid, arXiv, medRxiv, and bioRxiv up to 5 May 2020.},
  langid = {english},
  file = {C\:\\Users\\USER\\Zotero\\storage\\JKHNDVQ6\\Wynants et al. - 2020 - Prediction models for diagnosis and prognosis of c.pdf}
}

@article{yonOpenSourceTools2021,
  title = {5 {{Open Source Tools You Can Use}} to {{Train}} and {{Deploy}} an {{OCR Project}}},
  author = {Yon, Lai Woen},
  date = {2021-11-30},
  journaltitle = {Towards Data Science},
  url = {https://towardsdatascience.com/5-open-source-tools-you-can-use-to-train-and-deploy-an-ocr-project-8f204dec862b},
  abstract = {Part I: If you are doing text detection, you should know these tools}
}

@inproceedings{zhizhongmaExperimentalEvaluationMobile2013,
  title = {Experimental Evaluation of Mobile Phone Sensors},
  booktitle = {24th {{IET Irish Signals}} and {{Systems Conference}} ({{ISSC}} 2013)},
  author = {{Zhizhong Ma} and {Yuansong Qiao} and Lee, B. and Fallon, E.},
  date = {2013},
  pages = {49--49},
  publisher = {{Institution of Engineering and Technology}},
  location = {{Letterkenny, Ireland}},
  doi = {10.1049/ic.2013.0047},
  url = {https://digital-library.theiet.org/content/conferences/10.1049/ic.2013.0047},
  urldate = {2022-03-18},
  abstract = {Smart phone has become an important part of people's daily life. Most of current smart phone are equipped with a rich set of built-in sensors. The mobile applications such as geo-location based video annotation and indoor positioning require precise measurements from sensors. In addition, understanding the sensing performance of a smart phone device is helpful for implementing a mobile application that needs sensor data. This paper presents an experimental evaluation of key sensors in a state of the art smart phone –Google Nexus 4. The sensors chosen in the paper are accelerometer, gyroscope, magnetometer and GPS. Substantial tests have been executed to evaluate the sensors’ accuracy, precision, maximum sampling frequency, sampling period jitter, energy consumption.},
  eventtitle = {24th {{IET Irish Signals}} and {{Systems Conference}} ({{ISSC}} 2013)},
  isbn = {978-1-84919-754-0},
  langid = {english},
  file = {C\:\\Users\\USER\\Zotero\\storage\\AUAL7PLU\\Zhizhong Ma et al. - 2013 - Experimental evaluation of mobile phone sensors.pdf}
}

@inproceedings{zhuUnpairedImagetoImageTranslation2017,
  title = {Unpaired {{Image-to-Image Translation Using Cycle-Consistent Adversarial Networks}}},
  booktitle = {2017 {{IEEE International Conference}} on {{Computer Vision}} ({{ICCV}})},
  author = {Zhu, Jun-Yan and Park, Taesung and Isola, Phillip and Efros, Alexei A.},
  date = {2017-10},
  pages = {2242--2251},
  publisher = {{IEEE}},
  location = {{Venice}},
  doi = {10.1109/ICCV.2017.244},
  url = {http://ieeexplore.ieee.org/document/8237506/},
  urldate = {2022-06-02},
  abstract = {Image-to-image translation is a class of vision and graphics problems where the goal is to learn the mapping between an input image and an output image using a training set of aligned image pairs. However, for many tasks, paired training data will not be available. We present an approach for learning to translate an image from a source domain X to a target domain Y in the absence of paired examples. Our goal is to learn a mapping G : X → Y such that the distribution of images from G(X) is indistinguishable from the distribution Y using an adversarial loss. Because this mapping is highly under-constrained, we couple it with an inverse mapping F : Y → X and introduce a cycle consistency loss to enforce F (G(X)) ≈ X (and vice versa). Qualitative results are presented on several tasks where paired training data does not exist, including collection style transfer, object transfiguration, season transfer, photo enhancement, etc. Quantitative comparisons against several prior methods demonstrate the superiority of our approach.},
  eventtitle = {2017 {{IEEE International Conference}} on {{Computer Vision}} ({{ICCV}})},
  isbn = {978-1-5386-1032-9},
  langid = {english},
  file = {C\:\\Users\\USER\\Zotero\\storage\\KG68S2RS\\Zhu et al. - 2017 - Unpaired Image-to-Image Translation Using Cycle-Co.pdf}
}

@article{zotero-43,
  type = {article}
}
